\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{*}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\@writefile{toc}{\contentsline {chapter}{Todo list}{1}{section*.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{id:FromTapestryToSVD}
\citation{id:EvolutionOfRecommenderSystems}
\citation{id:NetflixPrize}
\citation{id:NetflixPrizeRankings}
\citation{id:NetflixPrize2}
\citation{id:NetflixPrizeRules}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 1\relax .\kern .5em Wst\IeC {\k e}p}{3}{section*.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (P\IeC {\'O}\IeC {\'Z}NIEJ) CEL PRACY: trzeba rozszerzy\IeC {\'c} opis, w szczeg\IeC {\'o}lno\IeC {\'s}ci o to, co jest nowego i czym r\IeC {\'o}\IeC {\.z}ni si\IeC {\k e} od innych ju\IeC {\.z} istniej\IeC {\k a}cych algorytm\IeC {\'o}w}{4}{section*.4}}
\pgfsyspdfmark {pgfid1}{5816759}{42620499}
\pgfsyspdfmark {pgfid2}{2120848}{42637429}
\pgfsyspdfmark {pgfid3}{3787442}{42366547}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (P\IeC {\'O}\IeC {\'Z}NIEJ) streszczenie spisu tre\IeC {\'s}ci}{4}{section*.5}}
\pgfsyspdfmark {pgfid6}{5816759}{38819411}
\pgfsyspdfmark {pgfid7}{2120848}{35647625}
\pgfsyspdfmark {pgfid8}{3787442}{35376743}
\citation{id:TheYouTubeVideoRecommendationSystem}
\citation{id:mgp}
\citation{id:aStreamOfMovies}
\citation{id:filmwebfaq}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 2\relax .\kern .5em Przegl\IeC {\k a}d istniej\IeC {\k a}cych rozwi\IeC {\k a}za\IeC {\'n}}{5}{section*.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.1\relax .\kern .5em }Rekomendacja muzyki}{5}{subsection.2.0.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.2\relax .\kern .5em }Rekomendacja film\IeC {\'o}w}{5}{subsection.2.0.2}}
\citation{id:imdbstats}
\citation{id:allegrofaq}
\citation{id:linden2003amazon}
\citation{id:IntroductionToRecommenderSystemsHandbook}
\citation{id:IntroductionToRecommenderSystemsHandbook}
\citation{id:CollaborativeFilteringRecommenderSystems}
\citation{id:huynh2012modeling}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.3\relax .\kern .5em }Platformy typu e-commerce}{6}{subsection.2.0.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1\relax .\kern .5em }Techniki rekomendacji}{6}{section.2.1}}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{id:ComprehensiveSurveyOfNeighborhoodBasedRecommendationMethods}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{melville2002content}
\@writefile{toc}{\contentsline {section}{\numberline {2.2\relax .\kern .5em }Filtrowanie kolaboratywne}{7}{section.2.2}}
\newlabel{s:filtrowaniekolaboratywne}{{2.2}{7}{}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Filtrowanie kolaboratywne metod\IeC {\k a} s\IeC {\k a}siedztwa, zorientowane na u\IeC {\.z}ytkownika \cite {koren2009matrix}.\relax }}{7}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cf}{{2.1}{7}{Filtrowanie kolaboratywne metodą sąsiedztwa, zorientowane na użytkownika \protect \cite {koren2009matrix}.\relax }{figure.caption.7}{}}
\citation{pariser2011filter}
\citation{id:NewRecommentationAlgoritmBasedOnSocialNetwork}
\citation{id:NextSongRecommendationWithTemporalDynamics}
\citation{koren2009matrix}
\citation{id:RubensRecSysHB2010}
\citation{id:zhang2015hybrid}
\citation{id:celma2010music}
\citation{id:RubensRecSysHB2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Filtrowanie kolaboratywne z wykorzystaniem modelu ukrytych parametr\IeC {\'o}w \cite {koren2009matrix}.\relax }}{8}{figure.caption.8}}
\newlabel{fig:cf2}{{2.2}{8}{Filtrowanie kolaboratywne z wykorzystaniem modelu ukrytych parametrów \protect \cite {koren2009matrix}.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1\relax .\kern .5em }Zalety filtrowania kolaboratywnego}{8}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2\relax .\kern .5em }Wady filtrowania kolaboratywnego}{8}{subsection.2.2.2}}
\citation{id:RubensRecSysHB2010}
\citation{id:RubensRecSysHB2010}
\citation{id:gupta2013wtf}
\citation{mymedialite}
\citation{gantner2011mymedialite}
\citation{koren2008factorization}
\citation{salakhutdinov2011probabilistic}
\citation{rendle2008online}
\citation{bell2007modeling}
\citation{lemire2005slope}
\citation{koren2010factor}
\citation{mymedialitedatasets}
\citation{mymedialitedatasets}
\citation{harper2016movielens}
\citation{id:ComputingRecommendationsExtremeScaleApacheFlink}
\citation{id:ComputingRecommendationsExtremeScaleApacheFlink}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Problem d\IeC {\l }ugiego ogona: 50\% ocen dotyczy 10-12\% najpopularniejszych element\IeC {\'o}w w systemie \cite {id:RubensRecSysHB2010}.\relax }}{9}{figure.caption.9}}
\newlabel{fig:longtail}{{2.3}{9}{Problem długiego ogona: 50\% ocen dotyczy 10-12\% najpopularniejszych elementów w systemie \protect \cite {id:RubensRecSysHB2010}.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3\relax .\kern .5em }Algorytmy filtrowania kolaboratywnego}{9}{subsection.2.2.3}}
\citation{koren2009matrix}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Test algorytm\IeC {\'o}w filtrowania kolaboratywnego \cite {mymedialitedatasets}\relax }}{10}{figure.caption.10}}
\newlabel{fig:cfcomparision}{{2.4}{10}{Test algorytmów filtrowania kolaboratywnego \protect \cite {mymedialitedatasets}\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Faktoryzacja macierzy \cite {id:ComputingRecommendationsExtremeScaleApacheFlink}\relax }}{10}{figure.caption.12}}
\newlabel{fig:factorization}{{2.5}{10}{Faktoryzacja macierzy \protect \cite {id:ComputingRecommendationsExtremeScaleApacheFlink}\relax }{figure.caption.12}{}}
\citation{bottou2012stochastic}
\citation{effandpractstochsub}
\citation{effandpractstochsub}
\newlabel{eq:sgd1}{{2.1}{11}{}{equation.2.2.1}{}}
\newlabel{eq:sgd2}{{2.2}{11}{}{equation.2.2.2}{}}
\newlabel{eq:sgd3}{{2.3}{11}{}{equation.2.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}Stochastyczny gradient prosty}{11}{algorithm.1}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {1}Stochastyczny gradient prosty}{11}{algorithm.1}}
\newlabel{aq:sgd}{{1}{11}{}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces R\IeC {\'o}\IeC {\.z}nica pomi\IeC {\k e}dzy klasycznym gradientem prostym (po lewej) a jego stochastyczn\IeC {\k a} wersj\IeC {\k a} (po prawej) \cite {effandpractstochsub}\relax }}{12}{figure.caption.14}}
\newlabel{fig:sgd}{{2.6}{12}{Różnica pomiędzy klasycznym gradientem prostym (po lewej) a jego stochastyczną wersją (po prawej) \protect \cite {effandpractstochsub}\relax }{figure.caption.14}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}Matrix Factorization -- Inicjacja modelu}{12}{algorithm.2}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {2}Matrix Factorization -- Inicjacja modelu}{12}{algorithm.2}}
\newlabel{aq:mf_init}{{2}{12}{}{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}Matrix Factorization -- Faza uczenia}{13}{algorithm.3}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {3}Matrix Factorization -- Faza uczenia}{13}{algorithm.3}}
\newlabel{aq:mf_learn}{{3}{13}{}{algorithm.3}{}}
\newlabel{eq:global_bias}{{2.4}{13}{}{equation.2.2.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}Biased Matrix Factorization -- Faza uczenia}{14}{algorithm.4}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {4}Biased Matrix Factorization -- Faza uczenia}{14}{algorithm.4}}
\newlabel{aq:bmf_learn}{{4}{14}{}{algorithm.4}{}}
\newlabel{eq:svd}{{2.5}{14}{}{equation.2.2.5}{}}
\citation{koren2008factorization}
\citation{id:huynh2012modeling}
\citation{id:ContentBasedRecommenderSystemsState}
\citation{id:MaleszkaMianowskaNguyenmethod}
\citation{id:ContentBasedRecommenderSystemsState}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{id:ContentBasedRecommenderSystemsState}
\@writefile{toc}{\contentsline {section}{\numberline {2.3\relax .\kern .5em }Filtrowanie z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{15}{section.2.3}}
\newlabel{s:filtrowaniezanalizazawartosci}{{2.3}{15}{}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1\relax .\kern .5em }Zalety filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{15}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2\relax .\kern .5em }Wady filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{15}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3\relax .\kern .5em }Metody tworzenia profilu u\IeC {\.z}ytkownika}{15}{subsection.2.3.3}}
\newlabel{ss:metody_tworzenia_profilu_uzytkownika}{{2.3.3}{15}{}{subsection.2.3.3}{}}
\citation{kwateralgorytmy}
\citation{kwateralgorytmy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4\relax .\kern .5em }Algorytmy wykorzystywane w implementacji filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{16}{subsection.2.3.4}}
\newlabel{sss:backprop}{{2.3.4}{16}{}{subsubsection*.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Algorytm propagacji wstecznej w sieci tr\IeC {\'o}jwarstwowej -- idea dzia\IeC {\l }ania \cite {kwateralgorytmy}\relax }}{16}{figure.caption.19}}
\newlabel{fig:ilustracjabackprop}{{2.7}{16}{Algorytm propagacji wstecznej w sieci trójwarstwowej -- idea działania \protect \cite {kwateralgorytmy}\relax }{figure.caption.19}{}}
\newlabel{eq:weightadaptation3}{{2.6}{16}{}{equation.2.3.6}{}}
\newlabel{eq:weightadaptation2}{{2.7}{16}{}{equation.2.3.7}{}}
\citation{haykin1994neural}
\citation{hertz1993wstkep}
\citation{kwateralgorytmy}
\citation{osowski1996sieci}
\citation{timothy1996sieci}
\newlabel{eq:weightadaptation4}{{2.8}{17}{}{equation.2.3.8}{}}
\newlabel{sss:metoda_momentum}{{2.3.4}{17}{}{subsubsection*.21}{}}
\newlabel{eq:zasadamomentum1}{{2.9}{17}{}{equation.2.3.9}{}}
\newlabel{eq:zasadamomentum2}{{2.10}{17}{}{equation.2.3.10}{}}
\citation{riedmiller1993direct}
\citation{riedmiller1994rprop}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Algorytm propagacji wstecznej\relax }}{18}{figure.caption.20}}
\newlabel{fig:propagacjawsteczna}{{2.8}{18}{Algorytm propagacji wstecznej\relax }{figure.caption.20}{}}
\newlabel{eq:rprop}{{2.11}{18}{}{equation.2.3.11}{}}
\citation{pena2000evolutionary}
\citation{aforgenetgenetic}
\citation{montana1989training}
\citation{claypool1999combining}
\newlabel{ss:algorytm_genetyczny}{{2.3.4}{19}{}{subsubsection*.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Og\IeC {\'o}lny schemat algorytmu genetycznego\relax }}{19}{figure.caption.24}}
\newlabel{fig:algorytmgenetyczny}{{2.9}{19}{Ogólny schemat algorytmu genetycznego\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4\relax .\kern .5em }Algorytmy hybrydowe}{19}{section.2.4}}
\newlabel{s:algorytmyhybrydowe}{{2.4}{19}{}{section.2.4}{}}
\citation{adomavicius2005toward}
\citation{basu1998recommendation}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 3\relax .\kern .5em Algorytmy}{21}{section*.25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1\relax .\kern .5em }Model systemu}{21}{section.3.1}}
\citation{aforgenet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Model czarnoskrzynkowy\relax }}{22}{figure.caption.26}}
\newlabel{fig:blackbox}{{3.1}{22}{Model czarnoskrzynkowy\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Uog\IeC {\'o}lniony model elementu\relax }}{22}{figure.caption.27}}
\newlabel{fig:modelElementu}{{3.2}{22}{Uogólniony model elementu\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Uog\IeC {\'o}lniony model elementu\relax }}{22}{figure.caption.28}}
\newlabel{fig:modelUsera}{{3.3}{22}{Uogólniony model elementu\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2\relax .\kern .5em }Propozycja algorytmu filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{22}{section.3.2}}
\newlabel{s:propozycjaalgorytmucbf}{{3.2}{22}{}{section.3.2}{}}
\citation{aforgenet}
\citation{aforgenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1\relax .\kern .5em }Struktura perceptron\IeC {\'o}w i funkcja aktywacji}{23}{subsection.3.2.1}}
\newlabel{sss:strukturaperceptronow}{{3.2.1}{23}{}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Schemat perceptronu\relax }}{23}{figure.caption.29}}
\newlabel{fig:schematneuronu}{{3.4}{23}{Schemat perceptronu\relax }{figure.caption.29}{}}
\newlabel{eq:neuroneq}{{3.1}{23}{}{equation.3.2.1}{}}
\newlabel{eq:sigmoidal}{{3.2}{23}{}{equation.3.2.2}{}}
\citation{osowski1996sieci}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Wykres sigmoidalnej funkcji aktywacji perceptronu \cite {aforgenet}\relax }}{24}{figure.caption.30}}
\newlabel{fig:sigmoid}{{3.5}{24}{Wykres sigmoidalnej funkcji aktywacji perceptronu \protect \cite {aforgenet}\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2\relax .\kern .5em }Struktura sieci i przebieg algorytmu}{24}{subsection.3.2.2}}
\newlabel{ss:strukturasiecineuronowej}{{3.2.2}{24}{}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3\relax .\kern .5em }Uczenie sieci neuronowej}{24}{subsection.3.2.3}}
\newlabel{ss:uczeniesiecineuronowej}{{3.2.3}{24}{}{subsection.3.2.3}{}}
\newlabel{eq:weightadaptation}{{3.3}{24}{}{equation.3.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Schemat sieci neuronowej\relax }}{25}{figure.caption.31}}
\newlabel{fig:siecneuronowa}{{3.6}{25}{Schemat sieci neuronowej\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Mapa cech elementu. Wiadomo, \IeC {\.z}e element X zawiera cech\IeC {\k e} ,,Aktor'' o warto\IeC {\'s}ciach ,,Julia Roberts, Al Pacino'' oraz cech\IeC {\k e} ,,Re\IeC {\.z}yser'' o warto\IeC {\'s}ci ,,Francis Ford Coppola''. Element nie zawiera cechy ,,Aktor'' o warto\IeC {\'s}ci ,,Brad Pitt'' ani cechy ,,Re\IeC {\.z}yser'' o warto\IeC {\'s}ci ,,Darren Aronofsky'' wi\IeC {\k e}c w te miejsca wstawiane jest $0$.\relax }}{25}{figure.caption.32}}
\newlabel{fig:mapacech}{{3.7}{25}{Mapa cech elementu. Wiadomo, że element X zawiera cechę ,,Aktor'' o wartościach ,,Julia Roberts, Al Pacino'' oraz cechę ,,Reżyser'' o wartości ,,Francis Ford Coppola''. Element nie zawiera cechy ,,Aktor'' o wartości ,,Brad Pitt'' ani cechy ,,Reżyser'' o wartości ,,Darren Aronofsky'' więc w te miejsca wstawiane jest $0$.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3\relax .\kern .5em }Propozycja nowych algorytm\IeC {\'o}w hybrydowych}{26}{section.3.3}}
\newlabel{eq:hybrid}{{3.4}{26}{}{equation.3.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Wp\IeC {\l }yw parametru $k$ na wynik algorytmu. Je\IeC {\.z}eli parametr $k=2$ a uczenie sieci neuronowej zako\IeC {\'n}czy\IeC {\l }o si\IeC {\k e} z b\IeC {\l }\IeC {\k e}dem r\IeC {\'o}wnym $d=1,2$, to ko\IeC {\'n}cowy stosunek wag wyniku filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci do wyniku filtrowania kolaboratywnego wyniesie ok. 43,5\% do 56,5\%.\relax }}{26}{figure.caption.33}}
\newlabel{fig:hybridfunction}{{3.8}{26}{Wpływ parametru $k$ na wynik algorytmu. Jeżeli parametr $k=2$ a uczenie sieci neuronowej zakończyło się z błędem równym $d=1,2$, to końcowy stosunek wag wyniku filtrowania z analizą zawartości do wyniku filtrowania kolaboratywnego wyniesie ok. 43,5\% do 56,5\%.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1\relax .\kern .5em }Zalety zaproponowanych metod}{27}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2\relax .\kern .5em }Wady zaproponowanych metod}{28}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 4\relax .\kern .5em Ocena eksperymentalna}{29}{section*.34}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1\relax .\kern .5em }Opis metody badawczej}{29}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}Przebieg eksperymentu}{29}{algorithm.5}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {5}Przebieg eksperymentu}{29}{algorithm.5}}
\newlabel{aq:experiment}{{5}{29}{}{algorithm.5}{}}
\citation{hyndman2006another}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1\relax .\kern .5em }Miara oceny}{30}{subsection.4.1.1}}
\newlabel{eq:rmse}{{4.1}{30}{}{equation.4.1.1}{}}
\citation{hyndman2006another}
\citation{harper2016movielens}
\citation{amazonmeta}
\citation{leskovec2007dynamics}
\newlabel{eq:mae}{{4.2}{31}{}{equation.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2\relax .\kern .5em }Zbiory danych}{31}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Schemat bazy MovieLens\relax }}{32}{figure.caption.38}}
\newlabel{fig:movielens_schema}{{4.1}{32}{Schemat bazy MovieLens\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2\relax .\kern .5em }\IeC {\'S}rodowisko symulacyjne}{32}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1\relax .\kern .5em }Oprogramowanie}{32}{subsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Zrzut ekranu \IeC {\'s}rodowiska symulacyjnego\relax }}{33}{figure.caption.40}}
\newlabel{fig:program}{{4.2}{33}{Zrzut ekranu środowiska symulacyjnego\relax }{figure.caption.40}{}}
\gdef \LT@i {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2\relax .\kern .5em }Sprz\IeC {\k e}t}{34}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3\relax .\kern .5em }Eksperymentalne dopasowanie parametr\IeC {\'o}w sieci neuronowej}{34}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1\relax .\kern .5em }Strojenie sieci dla bazy MovieLens}{34}{subsection.4.3.1}}
\newlabel{ss:strojeniemovielens}{{4.3.1}{34}{}{subsection.4.3.1}{}}
\newlabel{exp:expiterations}{{4.3.1}{34}{}{subsubsection*.41}{}}
\gdef \LT@ii {\LT@entry 
    {1}{59.25122pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{36.03738pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{81.70184pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Konfiguracja dla eksperymentu maksymalnej liczby iteracji\relax }}{35}{table.4.1}}
\newlabel{tab:expiterations}{{4.2}{35}{}{table.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu wyra\IeC {\.z}onego za pomoc\IeC {\k a} RMSE i czasu wykonania od maksymalnej liczy iteracji (baza MovieLens).\relax }}{35}{table.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a b\IeC {\l }\IeC {\k e}dem algorytmu wyra\IeC {\.z}onym za pomoc\IeC {\k a} RMSE. Wraz ze wzrostem liczby iteracji warto\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du maleje, jednak\IeC {\.z}e po przekroczeniu pewnej warto\IeC {\'s}ci nast\IeC {\k e}puje ponowny wzrost. Wynika to z wyst\IeC {\k e}powania zjawiska nadmiernego dopasowania (ang. \textit  {overfitting}). \relax }}{35}{figure.caption.42}}
\newlabel{fig:expiterations_rmse}{{4.3}{35}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zależność pomiędzy liczbą iteracji a błędem algorytmu wyrażonym za pomocą RMSE. Wraz ze wzrostem liczby iteracji wartość błędu maleje, jednakże po przekroczeniu pewnej wartości następuje ponowny wzrost. Wynika to z występowania zjawiska nadmiernego dopasowania (ang. \textit {overfitting}). \relax }{figure.caption.42}{}}
\gdef \LT@iii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a czasem wykonania. Zgodnie z oczekiwaniami, czas wykonania jest wprost proporcjonalny do liczby iteracji. W trakcie tego eksperymentu potwierdzone zosta\IeC {\l }y r\IeC {\'o}wnie\IeC {\.z} przypuszczenia dotycz\IeC {\k a}ce pr\IeC {\k e}dko\IeC {\'s}ci dzia\IeC {\l }ania algorytm\IeC {\'o}w. Najszybszy okaza\IeC {\l } si\IeC {\k e} RPROP, jednak\IeC {\.z}e kosztem nieco wi\IeC {\k e}kszych b\IeC {\l }\IeC {\k e}d\IeC {\'o}w. Najgorzej wypad\IeC {\l } algorytm genetyczny, kt\IeC {\'o}ry charakteryzowa\IeC {\l } si\IeC {\k e} bardzo szybko rosn\IeC {\k a}cym czasem wykonania przy jednoczesnym nie najlepszym wynikiem RMSE. \relax }}{36}{figure.caption.43}}
\newlabel{fig:expiterations_time}{{4.4}{36}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zależność pomiędzy liczbą iteracji a czasem wykonania. Zgodnie z oczekiwaniami, czas wykonania jest wprost proporcjonalny do liczby iteracji. W trakcie tego eksperymentu potwierdzone zostały również przypuszczenia dotyczące prędkości działania algorytmów. Najszybszy okazał się RPROP, jednakże kosztem nieco większych błędów. Najgorzej wypadł algorytm genetyczny, który charakteryzował się bardzo szybko rosnącym czasem wykonania przy jednoczesnym nie najlepszym wynikiem RMSE. \relax }{figure.caption.43}{}}
\newlabel{exp:momentum}{{4.3.1}{36}{}{subsubsection*.44}{}}
\gdef \LT@iv {\LT@entry 
    {1}{86.55678pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Konfiguracja dla eksperymentu dopasowania warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci\relax }}{37}{table.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymaln\IeC {\k a} warto\IeC {\'s}\IeC {\'c} wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy warto\IeC {\'s}ci\IeC {\k a} parametru a b\IeC {\l }\IeC {\k e}dem RMSE. W zakresie warto\IeC {\'s}ci $[0,0.9]$ b\IeC {\l }\IeC {\k a}d oscyluje w granicach podobnych warto\IeC {\'s}ci z nieznaczn\IeC {\k a} tendencj\IeC {\k a} malej\IeC {\k a}c\IeC {\k a}. Wyra\IeC {\'z}ny skok na niekorzy\IeC {\'s}\IeC {\'c} odnotowany jest dopiero przy momentum$=1$.\relax }}{37}{figure.caption.45}}
\newlabel{fig:expmomentum}{{4.5}{37}{Wyniki eksperymentu testującego optymalną wartość współczynnika bezwładności na bazie MovieLens. Wykres przedstawia zależność pomiędzy wartością parametru a błędem RMSE. W zakresie wartości $[0,0.9]$ błąd oscyluje w granicach podobnych wartości z nieznaczną tendencją malejącą. Wyraźny skok na niekorzyść odnotowany jest dopiero przy momentum$=1$.\relax }{figure.caption.45}{}}
\newlabel{tab:expmomentum}{{4.4}{37}{}{table.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci (baza MovieLens).\relax }}{37}{table.4.4}}
\gdef \LT@v {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\gdef \LT@vi {\LT@entry 
    {1}{76.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.12457pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Konfiguracja dla eksperymentu dopasowania wielko\IeC {\'s}ci populacji\relax }}{38}{table.4.5}}
\newlabel{tab:exppopulation}{{4.6}{38}{}{table.4.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru populacji.\relax }}{38}{table.4.6}}
\gdef \LT@vii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar populacji na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem a b\IeC {\l }\IeC {\k e}dem RMSE. Zgodnie z oczekiwaniami wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem populacji a czasem wykonania i ujemna pomi\IeC {\k e}dzy rozmiarem populacji a b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem populacji a czasem wykonania jest liniowa, natomiast b\IeC {\l }\IeC {\k a}d maleje wyk\IeC {\l }adniczo gdy populacja osi\IeC {\k a}ga wi\IeC {\k e}ksze rozmiary. Optymalnym zatem jest przyj\IeC {\k e}cie rozmiaru populacji r\IeC {\'o}wnej $100$.\relax }}{39}{figure.caption.47}}
\newlabel{fig:exppopulation}{{4.6}{39}{Wyniki eksperymentu testującego optymalny rozmiar populacji na bazie MovieLens. Wykres przedstawia zależność pomiędzy rozmiarem a błędem RMSE. Zgodnie z oczekiwaniami występuje dodatnia korelacja pomiędzy rozmiarem populacji a czasem wykonania i ujemna pomiędzy rozmiarem populacji a błędem algorytmu rekomendacji. Zależność pomiędzy rozmiarem populacji a czasem wykonania jest liniowa, natomiast błąd maleje wykładniczo gdy populacja osiąga większe rozmiary. Optymalnym zatem jest przyjęcie rozmiaru populacji równej $100$.\relax }{figure.caption.47}{}}
\gdef \LT@viii {\LT@entry 
    {1}{92.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.5383pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w\relax }}{40}{table.4.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a b\IeC {\l }\IeC {\k e}dem RMSE. Wyniki prezentuj\IeC {\k a} si\IeC {\k e} odmiennie w zale\IeC {\.z}no\IeC {\'s}ci od typu algorytmu wykorzystanego do uczenia sieci. W przypadku algorytm\IeC {\'o}w propagacji wstecznej i RPROP wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem warstwy ukrytej a b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Dla algorytmu BackProp optymalny rezultat osi\IeC {\k a}gni\IeC {\k e}ty zosta\IeC {\l } dla zaledwie jednego neuronu w warstwie ukrytej, dla algorytmu RPROP dla pi\IeC {\k e}ciu neuron\IeC {\'o}w. W tym ostatnim przypadku poprawa znajduje si\IeC {\k e} jednak na marginesie b\IeC {\l }\IeC {\k e}du statystycznego. W przypadku algorytmu genetycznego, niezale\IeC {\.z}nie od ilo\IeC {\'s}ci neuron\IeC {\'o}w wynik oscyluje na podobnym poziomie w zakresie testowanych warto\IeC {\'s}ci.\relax }}{40}{figure.caption.49}}
\newlabel{fig:exphiddenneural}{{4.7}{40}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów na bazie MovieLens. Wykres przedstawia zależność pomiędzy ilością neuronów a błędem RMSE. Wyniki prezentują się odmiennie w zależności od typu algorytmu wykorzystanego do uczenia sieci. W przypadku algorytmów propagacji wstecznej i RPROP występuje dodatnia korelacja pomiędzy rozmiarem warstwy ukrytej a błędem algorytmu rekomendacji. Dla algorytmu BackProp optymalny rezultat osiągnięty został dla zaledwie jednego neuronu w warstwie ukrytej, dla algorytmu RPROP dla pięciu neuronów. W tym ostatnim przypadku poprawa znajduje się jednak na marginesie błędu statystycznego. W przypadku algorytmu genetycznego, niezależnie od ilości neuronów wynik oscyluje na podobnym poziomie w zakresie testowanych wartości.\relax }{figure.caption.49}{}}
\newlabel{tab:exphiddenneural}{{4.8}{40}{}{table.4.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru ukrytej warstwy neuronowej (baza MovieLens).\relax }}{40}{table.4.8}}
\gdef \LT@ix {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{251.85992pt}}
\gdef \LT@x {\LT@entry 
    {1}{59.25122pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.52457pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{81.70184pt}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (NA KO\IeC {\'N}CU, BADANIA) Czy trzeba?}{41}{section*.51}}
\pgfsyspdfmark {pgfid11}{6749098}{47109715}
\pgfsyspdfmark {pgfid14}{37004660}{47126645}
\pgfsyspdfmark {pgfid15}{38671254}{46855763}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (NA KO\IeC {\'N}CU, BADANIA) Czy trzeba}{41}{section*.53}}
\pgfsyspdfmark {pgfid16}{6749098}{44291667}
\pgfsyspdfmark {pgfid19}{37004660}{44308597}
\pgfsyspdfmark {pgfid20}{38671254}{44037715}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w\relax }}{41}{table.4.9}}
\newlabel{tab:optimummovielens}{{4.9}{41}{Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuronów\relax }{table.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2\relax .\kern .5em }Strojenie sieci dla bazy AmazonMeta}{41}{subsection.4.3.2}}
\newlabel{ss:strojenieamazonmeta}{{4.3.2}{41}{}{subsection.4.3.2}{}}
\newlabel{tab:am_expiterations}{{4.10}{41}{}{table.4.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu wyra\IeC {\.z}onego za pomoc\IeC {\k a} RMSE i czasu wykonania od maksymalnej liczy iteracji (baza AmazonMeta).\relax }}{41}{table.4.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a b\IeC {\l }\IeC {\k e}dem algorytmu wyra\IeC {\.z}onym za pomoc\IeC {\k a} RMSE. Pocz\IeC {\k a}tkowo warto\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du szybko maleje, jednak\IeC {\.z}e wraz ze wzrostem liczby iteracji k\IeC {\k a}ty nachylenia kolejnych odcink\IeC {\'o}w krzywej ulegaj\IeC {\k a} zwi\IeC {\k e}kszeniu. Bior\IeC {\k a}c pod uwag\IeC {\k e} rosn\IeC {\k a}cy liniowo czas wykonania (zob. \ref  {fig:am_expiterations_time}) w pewnym momencie koszt w postaci czasu wykonania przewy\IeC {\.z}sza korzy\IeC {\'s}\IeC {\'c} wynikaj\IeC {\k a}c\IeC {\k a} z ni\IeC {\.z}szego b\IeC {\l }\IeC {\k e}du RMSE. W zakresach liczby iteracji od 100 do 2000 wyst\IeC {\k e}puj\IeC {\k a} nieznaczne zachwiania, kt\IeC {\'o}re znajduj\IeC {\k a} si\IeC {\k e} w zakresie b\IeC {\l }\IeC {\k e}du statystycznego. \relax }}{42}{figure.caption.56}}
\newlabel{fig:am_expiterations_rmse}{{4.8}{42}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy liczbą iteracji a błędem algorytmu wyrażonym za pomocą RMSE. Początkowo wartość błędu szybko maleje, jednakże wraz ze wzrostem liczby iteracji kąty nachylenia kolejnych odcinków krzywej ulegają zwiększeniu. Biorąc pod uwagę rosnący liniowo czas wykonania (zob. \ref {fig:am_expiterations_time}) w pewnym momencie koszt w postaci czasu wykonania przewyższa korzyść wynikającą z niższego błędu RMSE. W zakresach liczby iteracji od 100 do 2000 występują nieznaczne zachwiania, które znajdują się w zakresie błędu statystycznego. \relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a czasem wykonania. Czas wykonania jest wprost proporcjonalny do liczby iteracji. \relax }}{42}{figure.caption.57}}
\newlabel{fig:am_expiterations_time}{{4.9}{42}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy liczbą iteracji a czasem wykonania. Czas wykonania jest wprost proporcjonalny do liczby iteracji. \relax }{figure.caption.57}{}}
\gdef \LT@xi {\LT@entry 
    {1}{86.55678pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymaln\IeC {\k a} warto\IeC {\'s}\IeC {\'c} wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy warto\IeC {\'s}ci\IeC {\k a} parametru a b\IeC {\l }\IeC {\k e}dem RMSE. W zakresie warto\IeC {\'s}ci $[0,0.9]$ b\IeC {\l }\IeC {\k a}d oscyluje w granicach podobnych warto\IeC {\'s}ci z nieznaczn\IeC {\k a} tendencj\IeC {\k a} malej\IeC {\k a}c\IeC {\k a}. Wyra\IeC {\'z}ny skok na niekorzy\IeC {\'s}\IeC {\'c} odnotowany jest dopiero przy momentum$=1$.\relax }}{43}{figure.caption.59}}
\newlabel{fig:am_expmomentum}{{4.10}{43}{Wyniki eksperymentu testującego optymalną wartość współczynnika bezwładności na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy wartością parametru a błędem RMSE. W zakresie wartości $[0,0.9]$ błąd oscyluje w granicach podobnych wartości z nieznaczną tendencją malejącą. Wyraźny skok na niekorzyść odnotowany jest dopiero przy momentum$=1$.\relax }{figure.caption.59}{}}
\newlabel{tab:am_expmomentum}{{4.11}{43}{}{table.4.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci (baza AmazonMeta).\relax }}{43}{table.4.11}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ wstawi\IeC {\'c} tabelk\IeC {\k e}}{43}{section*.62}}
\pgfsyspdfmark {pgfid21}{6749098}{4915651}
\pgfsyspdfmark {pgfid24}{37004660}{4932581}
\pgfsyspdfmark {pgfid25}{38671254}{4661699}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar populacji na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem a b\IeC {\l }\IeC {\k e}dem RMSE. Zgodnie z oczekiwaniami wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem populacji a czasem wykonania i ujemna pomi\IeC {\k e}dzy rozmiarem populacji a b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem populacji a czasem wykonania jest liniowa, natomiast b\IeC {\l }\IeC {\k a}d maleje wyk\IeC {\l }adniczo gdy populacja osi\IeC {\k a}ga wi\IeC {\k e}ksze rozmiary. Optymalnym zatem jest przyj\IeC {\k e}cie rozmiaru populacji r\IeC {\'o}wnej $50$ tak, aby czas wykonania nie przekracza\IeC {\l } 200000ms.\relax }}{44}{figure.caption.61}}
\newlabel{fig:am_exppopulation}{{4.11}{44}{Wyniki eksperymentu testującego optymalny rozmiar populacji na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy rozmiarem a błędem RMSE. Zgodnie z oczekiwaniami występuje dodatnia korelacja pomiędzy rozmiarem populacji a czasem wykonania i ujemna pomiędzy rozmiarem populacji a błędem algorytmu rekomendacji. Zależność pomiędzy rozmiarem populacji a czasem wykonania jest liniowa, natomiast błąd maleje wykładniczo gdy populacja osiąga większe rozmiary. Optymalnym zatem jest przyjęcie rozmiaru populacji równej $50$ tak, aby czas wykonania nie przekraczał 200000ms.\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a b\IeC {\l }\IeC {\k e}dem RMSE. W przypadku algorytm\IeC {\'o}w propagacji wstecznej i RPROP wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem warstwy ukrytej a b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Dla algorytmu BackProp optymalne wyniki osi\IeC {\k a}gni\IeC {\k e}te zosta\IeC {\l }y dla zaledwie liczby neuron\IeC {\'o}w w warstwie ukrytej nie przekraczaj\IeC {\k a}cej 5, dla algorytmu RPROP dla nie przekraczaj\IeC {\k a}cej 20. W przypadku algorytmu genetycznego, niezale\IeC {\.z}nie od ilo\IeC {\'s}ci neuron\IeC {\'o}w wynik oscyluje na podobnym poziomie w zakresie testowanych warto\IeC {\'s}ci.\relax }}{45}{figure.caption.64}}
\newlabel{fig:am_exphiddenneural_rmse}{{4.12}{45}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy ilością neuronów a błędem RMSE. W przypadku algorytmów propagacji wstecznej i RPROP występuje dodatnia korelacja pomiędzy rozmiarem warstwy ukrytej a błędem algorytmu rekomendacji. Dla algorytmu BackProp optymalne wyniki osiągnięte zostały dla zaledwie liczby neuronów w warstwie ukrytej nie przekraczającej 5, dla algorytmu RPROP dla nie przekraczającej 20. W przypadku algorytmu genetycznego, niezależnie od ilości neuronów wynik oscyluje na podobnym poziomie w zakresie testowanych wartości.\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a czasem wykonania. Czas wykonania ro\IeC {\'s}nie liniowo proporcjonalnie do ilo\IeC {\'s}ci neuron\IeC {\'o}w. W zwi\IeC {\k a}zku z tym oraz bior\IeC {\k a}c pod uwag\IeC {\k e} wykres \ref  {fig:am_exphiddenneural_rmse} optymalnym jest ustalenie liczby neuron\IeC {\'o}w w warstwie ukrytej na 1.\relax }}{45}{figure.caption.65}}
\newlabel{fig:am_exphiddenneural_time}{{4.13}{45}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy ilością neuronów a czasem wykonania. Czas wykonania rośnie liniowo proporcjonalnie do ilości neuronów. W związku z tym oraz biorąc pod uwagę wykres \ref {fig:am_exphiddenneural_rmse} optymalnym jest ustalenie liczby neuronów w warstwie ukrytej na 1.\relax }{figure.caption.65}{}}
\gdef \LT@xii {\LT@entry 
    {1}{92.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.52457pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{52.87445pt}}
\gdef \LT@xiii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{267.58353pt}}
\newlabel{tab:am_exphiddenneural}{{4.12}{46}{}{table.4.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE i czasu wykonania od rozmiaru ukrytej warstwy neuronowej (baza AmazonMeta).\relax }}{46}{table.4.12}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ wstawi\IeC {\'c} tabelk\IeC {\k e}}{46}{section*.66}}
\pgfsyspdfmark {pgfid26}{5816759}{34635776}
\pgfsyspdfmark {pgfid27}{2120848}{34652706}
\pgfsyspdfmark {pgfid28}{3787442}{34381824}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (NA KO\IeC {\'N}CU, BADANIA) Czy trzeba?}{46}{section*.68}}
\pgfsyspdfmark {pgfid31}{5816759}{31817728}
\pgfsyspdfmark {pgfid32}{2120848}{31834658}
\pgfsyspdfmark {pgfid33}{3787442}{31563776}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (NA KO\IeC {\'N}CU, BADANIA) Czy trzeba?}{46}{section*.70}}
\pgfsyspdfmark {pgfid36}{5816759}{28999680}
\pgfsyspdfmark {pgfid37}{2120848}{29016610}
\pgfsyspdfmark {pgfid38}{3787442}{28745728}
\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w\relax }}{46}{table.4.13}}
\newlabel{tab:am_optimummovielens}{{4.13}{46}{Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuronów\relax }{table.4.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4\relax .\kern .5em }Eksperymentalne por\IeC {\'o}wnanie zaproponowanych algorytm\IeC {\'o}w hybrydowych z filtrowaniem z analiz\IeC {\k a} zawarto\IeC {\'s}ci i filtrowaniem kolaboratywnym}{47}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1\relax .\kern .5em }Eksperyment pierwszy - efektywno\IeC {\'s}\IeC {\'c} algorytm\IeC {\'o}w w zale\IeC {\.z}no\IeC {\'s}ci od minimum powtarzaj\IeC {\k a}cych si\IeC {\k e} cech element\IeC {\'o}w}{47}{subsection.4.4.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (BADANIA) Por\IeC {\'o}wnanie algorytmu hybrydowego z content-based i collaborative}{47}{section*.77}}
\pgfsyspdfmark {pgfid41}{6749098}{27743827}
\pgfsyspdfmark {pgfid44}{37004660}{27760757}
\pgfsyspdfmark {pgfid45}{38671254}{27489875}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2\relax .\kern .5em }Analiza statystyczna wynik\IeC {\'o}w}{47}{subsection.4.4.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (P\IeC {\'O}\IeC {\'Z}NIEJ) Analiza statystyczna wynik\IeC {\'o}w, PQStat}{47}{section*.82}}
\pgfsyspdfmark {pgfid46}{6749098}{24401491}
\pgfsyspdfmark {pgfid49}{37004660}{23204911}
\pgfsyspdfmark {pgfid50}{38671254}{22934029}
\newlabel{fig:exphybrid_movielens1a}{{\caption@xref {fig:exphybrid_movielens1a}{ on input line 1534}}{48}{}{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z analiz\IeC {\k a} zawarto\IeC {\'s}ci na podstawie danych z bazy MovieLense. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci.\relax }}{49}{figure.caption.73}}
\newlabel{fig:exphybrid_movielens1b}{{4.14}{49}{Porównanie algorytmu hybrydowego z analizą zawartości na podstawie danych z bazy MovieLense. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania z analizą zawartości.\relax }{figure.caption.73}{}}
\newlabel{fig:exphybrid_movielens2a}{{\caption@xref {fig:exphybrid_movielens2a}{ on input line 1550}}{50}{}{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy MovieLense. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania kolaboratywnego.\relax }}{51}{figure.caption.75}}
\newlabel{fig:exphybrid_movielens2b}{{4.15}{51}{Porównanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy MovieLense. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania kolaboratywnego.\relax }{figure.caption.75}{}}
\newlabel{fig:exphybrid_amazon1a}{{\caption@xref {fig:exphybrid_amazon1a}{ on input line 1575}}{52}{}{figure.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z analiz\IeC {\k a} zawarto\IeC {\'s}ci na podstawie danych z bazy AmazonMeta. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci.\relax }}{53}{figure.caption.79}}
\newlabel{fig:exphybrid_amazon1b}{{4.16}{53}{Porównanie algorytmu hybrydowego z analizą zawartości na podstawie danych z bazy AmazonMeta. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania z analizą zawartości.\relax }{figure.caption.79}{}}
\newlabel{fig:exphybrid_amazon2a}{{\caption@xref {fig:exphybrid_amazon2a}{ on input line 1591}}{54}{}{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy AmazonMeta. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania kolaboratywnego.\relax }}{55}{figure.caption.81}}
\newlabel{fig:exphybrid_amazon2b}{{4.17}{55}{Porównanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy AmazonMeta. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania kolaboratywnego.\relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 5\relax .\kern .5em Wnioski}{57}{section*.83}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Wnioski}{57}{section*.84}}
\pgfsyspdfmark {pgfid51}{6749098}{34068051}
\pgfsyspdfmark {pgfid54}{37004660}{34084981}
\pgfsyspdfmark {pgfid55}{38671254}{33814099}
\@writefile{toc}{\contentsline {chapter}{Dodatek\ A\relax .\kern .5em Appendix 1}{59}{section*.85}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{iisthesis}
\bibdata{bibliography}
\bibcite{id:mgp}{1}
\bibcite{adomavicius2005toward}{2}
\bibcite{id:allegrofaq}{3}
\bibcite{amazonmeta}{4}
\bibcite{effandpractstochsub}{5}
\bibcite{basu1998recommendation}{6}
\bibcite{bell2007modeling}{7}
\bibcite{bottou2012stochastic}{8}
\bibcite{id:celma2010music}{9}
\bibcite{id:NewRecommentationAlgoritmBasedOnSocialNetwork}{10}
\bibcite{claypool1999combining}{11}
\bibcite{id:TheYouTubeVideoRecommendationSystem}{12}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{61}{section*.87}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{id:ComprehensiveSurveyOfNeighborhoodBasedRecommendationMethods}{13}
\bibcite{id:filmwebfaq}{14}
\bibcite{mymedialite}{15}
\bibcite{gantner2011mymedialite}{16}
\bibcite{id:gupta2013wtf}{17}
\bibcite{harper2016movielens}{18}
\bibcite{haykin1994neural}{19}
\bibcite{hertz1993wstkep}{20}
\bibcite{id:FromTapestryToSVD}{21}
\bibcite{id:huynh2012modeling}{22}
\bibcite{hyndman2006another}{23}
\bibcite{id:imdbstats}{24}
\bibcite{id:NextSongRecommendationWithTemporalDynamics}{25}
\bibcite{aforgenet}{26}
\bibcite{aforgenetgenetic}{27}
\bibcite{koren2008factorization}{28}
\bibcite{koren2010factor}{29}
\bibcite{id:AdvancesInCollaborativeFiltering}{30}
\bibcite{koren2009matrix}{31}
\bibcite{kwateralgorytmy}{32}
\bibcite{lemire2005slope}{33}
\bibcite{leskovec2007dynamics}{34}
\bibcite{id:linden2003amazon}{35}
\bibcite{id:ContentBasedRecommenderSystemsState}{36}
\bibcite{id:MaleszkaMianowskaNguyenmethod}{37}
\bibcite{melville2002content}{38}
\bibcite{montana1989training}{39}
\bibcite{mymedialitedatasets}{40}
\bibcite{id:NetflixPrize}{41}
\bibcite{id:NetflixPrize2}{42}
\bibcite{id:NetflixPrizeRankings}{43}
\bibcite{id:NetflixPrizeRules}{44}
\bibcite{osowski1996sieci}{45}
\bibcite{pariser2011filter}{46}
\bibcite{pena2000evolutionary}{47}
\bibcite{id:aStreamOfMovies}{48}
\bibcite{rendle2008online}{49}
\bibcite{id:IntroductionToRecommenderSystemsHandbook}{50}
\bibcite{riedmiller1993direct}{51}
\bibcite{riedmiller1994rprop}{52}
\bibcite{id:ComputingRecommendationsExtremeScaleApacheFlink}{53}
\bibcite{id:RubensRecSysHB2010}{54}
\bibcite{salakhutdinov2011probabilistic}{55}
\bibcite{sarwar2000application}{56}
\bibcite{id:CollaborativeFilteringRecommenderSystems}{57}
\bibcite{id:EvolutionOfRecommenderSystems}{58}
\bibcite{timothy1996sieci}{59}
\bibcite{willmott2005advantages}{60}
\bibcite{yahoomusicwebsite}{61}
\bibcite{id:zhang2015hybrid}{62}
