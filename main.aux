\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{*}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\citation{id:FromTapestryToSVD}
\citation{id:EvolutionOfRecommenderSystems}
\citation{id:NetflixPrize}
\citation{id:NetflixPrizeRankings}
\citation{id:NetflixPrize2}
\citation{id:NetflixPrizeRules}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 1\relax .\kern .5em Wst\IeC {\k e}p}{1}{section*.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{id:TheYouTubeVideoRecommendationSystem}
\citation{id:mgp}
\citation{id:aStreamOfMovies}
\citation{id:filmwebfaq}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 2\relax .\kern .5em Przegl\IeC {\k a}d istniej\IeC {\k a}cych rozwi\IeC {\k a}za\IeC {\'n}}{3}{section*.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.1\relax .\kern .5em }Rekomendacja muzyki}{3}{subsection.2.0.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.2\relax .\kern .5em }Rekomendacja film\IeC {\'o}w}{3}{subsection.2.0.2}}
\citation{id:imdbstats}
\citation{id:allegrofaq}
\citation{id:linden2003amazon}
\citation{id:IntroductionToRecommenderSystemsHandbook}
\citation{id:IntroductionToRecommenderSystemsHandbook}
\citation{id:CollaborativeFilteringRecommenderSystems}
\citation{id:huynh2012modeling}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.3\relax .\kern .5em }Platformy typu e-commerce}{4}{subsection.2.0.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1\relax .\kern .5em }Techniki rekomendacji}{4}{section.2.1}}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{id:ComprehensiveSurveyOfNeighborhoodBasedRecommendationMethods}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{melville2002content}
\@writefile{toc}{\contentsline {section}{\numberline {2.2\relax .\kern .5em }Filtrowanie kolaboratywne}{5}{section.2.2}}
\newlabel{s:filtrowaniekolaboratywne}{{2.2}{5}{}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Filtrowanie kolaboratywne metod\IeC {\k a} s\IeC {\k a}siedztwa, zorientowane na u\IeC {\.z}ytkownika \cite {koren2009matrix}.\relax }}{5}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cf}{{2.1}{5}{Filtrowanie kolaboratywne metodą sąsiedztwa, zorientowane na użytkownika \protect \cite {koren2009matrix}.\relax }{figure.caption.3}{}}
\citation{pariser2011filter}
\citation{id:NewRecommentationAlgoritmBasedOnSocialNetwork}
\citation{id:NextSongRecommendationWithTemporalDynamics}
\citation{koren2009matrix}
\citation{id:RubensRecSysHB2010}
\citation{id:zhang2015hybrid}
\citation{id:celma2010music}
\citation{id:RubensRecSysHB2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Filtrowanie kolaboratywne z~wykorzystaniem modelu ukrytych parametr\IeC {\'o}w \cite {koren2009matrix}.\relax }}{6}{figure.caption.4}}
\newlabel{fig:cf2}{{2.2}{6}{Filtrowanie kolaboratywne z~wykorzystaniem modelu ukrytych parametrów \protect \cite {koren2009matrix}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1\relax .\kern .5em }Zalety filtrowania kolaboratywnego}{6}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2\relax .\kern .5em }Wady filtrowania kolaboratywnego}{6}{subsection.2.2.2}}
\citation{id:RubensRecSysHB2010}
\citation{id:RubensRecSysHB2010}
\citation{id:gupta2013wtf}
\citation{mymedialite}
\citation{gantner2011mymedialite}
\citation{koren2008factorization}
\citation{salakhutdinov2011probabilistic}
\citation{rendle2008online}
\citation{bell2007modeling}
\citation{lemire2005slope}
\citation{koren2010factor}
\citation{mymedialitedatasets}
\citation{mymedialitedatasets}
\citation{harper2016movielens}
\citation{id:ComputingRecommendationsExtremeScaleApacheFlink}
\citation{id:ComputingRecommendationsExtremeScaleApacheFlink}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Problem d\IeC {\l }ugiego ogona: 50\% ocen dotyczy 10-12\% najpopularniejszych element\IeC {\'o}w w~systemie \cite {id:RubensRecSysHB2010}.\relax }}{7}{figure.caption.5}}
\newlabel{fig:longtail}{{2.3}{7}{Problem długiego ogona: 50\% ocen dotyczy 10-12\% najpopularniejszych elementów w~systemie \protect \cite {id:RubensRecSysHB2010}.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3\relax .\kern .5em }Algorytmy filtrowania kolaboratywnego}{7}{subsection.2.2.3}}
\citation{koren2009matrix}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Test algorytm\IeC {\'o}w filtrowania kolaboratywnego \cite {mymedialitedatasets}\relax }}{8}{figure.caption.6}}
\newlabel{fig:cfcomparision}{{2.4}{8}{Test algorytmów filtrowania kolaboratywnego \protect \cite {mymedialitedatasets}\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Faktoryzacja macierzy \cite {id:ComputingRecommendationsExtremeScaleApacheFlink}\relax }}{8}{figure.caption.8}}
\newlabel{fig:factorization}{{2.5}{8}{Faktoryzacja macierzy \protect \cite {id:ComputingRecommendationsExtremeScaleApacheFlink}\relax }{figure.caption.8}{}}
\citation{bottou2012stochastic}
\citation{effandpractstochsub}
\citation{effandpractstochsub}
\newlabel{eq:sgd1}{{2.1}{9}{}{equation.2.2.1}{}}
\newlabel{eq:sgd2}{{2.2}{9}{}{equation.2.2.2}{}}
\newlabel{eq:sgd3}{{2.3}{9}{}{equation.2.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}Stochastyczny gradient prosty}{9}{algorithm.1}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {1}Stochastyczny gradient prosty}{9}{algorithm.1}}
\newlabel{aq:sgd}{{1}{9}{}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces R\IeC {\'o}\IeC {\.z}nica pomi\IeC {\k e}dzy klasycznym gradientem prostym (po lewej) a~jego stochastyczn\IeC {\k a} wersj\IeC {\k a} (po prawej) \cite {effandpractstochsub}\relax }}{10}{figure.caption.10}}
\newlabel{fig:sgd}{{2.6}{10}{Różnica pomiędzy klasycznym gradientem prostym (po lewej) a~jego stochastyczną wersją (po prawej) \protect \cite {effandpractstochsub}\relax }{figure.caption.10}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}Matrix Factorization -- Inicjacja modelu}{10}{algorithm.2}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {2}Matrix Factorization -- Inicjacja modelu}{10}{algorithm.2}}
\newlabel{aq:mf_init}{{2}{10}{}{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}Matrix Factorization -- Faza uczenia}{11}{algorithm.3}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {3}Matrix Factorization -- Faza uczenia}{11}{algorithm.3}}
\newlabel{aq:mf_learn}{{3}{11}{}{algorithm.3}{}}
\newlabel{eq:global_bias}{{2.4}{11}{}{equation.2.2.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}Biased Matrix Factorization -- Faza uczenia}{12}{algorithm.4}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {4}Biased Matrix Factorization -- Faza uczenia}{12}{algorithm.4}}
\newlabel{aq:bmf_learn}{{4}{12}{}{algorithm.4}{}}
\newlabel{eq:svd}{{2.5}{12}{}{equation.2.2.5}{}}
\citation{koren2008factorization}
\citation{id:huynh2012modeling}
\citation{id:ContentBasedRecommenderSystemsState}
\citation{id:MaleszkaMianowskaNguyenmethod}
\citation{id:ContentBasedRecommenderSystemsState}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{id:ContentBasedRecommenderSystemsState}
\@writefile{toc}{\contentsline {section}{\numberline {2.3\relax .\kern .5em }Filtrowanie z~analiz\IeC {\k a} zawarto\IeC {\'s}ci}{13}{section.2.3}}
\newlabel{s:filtrowaniezanalizazawartosci}{{2.3}{13}{}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1\relax .\kern .5em }Zalety filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci}{13}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2\relax .\kern .5em }Wady filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci}{13}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3\relax .\kern .5em }Metody tworzenia profilu u\IeC {\.z}ytkownika}{13}{subsection.2.3.3}}
\newlabel{ss:metody_tworzenia_profilu_uzytkownika}{{2.3.3}{13}{}{subsection.2.3.3}{}}
\citation{kwateralgorytmy}
\citation{kwateralgorytmy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4\relax .\kern .5em }Algorytmy wykorzystywane w~implementacji filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci}{14}{subsection.2.3.4}}
\newlabel{sss:backprop}{{2.3.4}{14}{}{subsubsection*.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Algorytm propagacji wstecznej w~sieci tr\IeC {\'o}jwarstwowej -- idea dzia\IeC {\l }ania \cite {kwateralgorytmy}\relax }}{14}{figure.caption.15}}
\newlabel{fig:ilustracjabackprop}{{2.7}{14}{Algorytm propagacji wstecznej w~sieci trójwarstwowej -- idea działania \protect \cite {kwateralgorytmy}\relax }{figure.caption.15}{}}
\newlabel{eq:weightadaptation3}{{2.6}{14}{}{equation.2.3.6}{}}
\newlabel{eq:weightadaptation2}{{2.7}{14}{}{equation.2.3.7}{}}
\citation{haykin1994neural}
\citation{hertz1993wstkep}
\citation{kwateralgorytmy}
\citation{osowski1996sieci}
\citation{timothy1996sieci}
\newlabel{eq:weightadaptation4}{{2.8}{15}{}{equation.2.3.8}{}}
\newlabel{sss:metoda_momentum}{{2.3.4}{15}{}{subsubsection*.17}{}}
\newlabel{eq:zasadamomentum1}{{2.9}{15}{}{equation.2.3.9}{}}
\newlabel{eq:zasadamomentum2}{{2.10}{15}{}{equation.2.3.10}{}}
\citation{riedmiller1993direct}
\citation{riedmiller1994rprop}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Algorytm propagacji wstecznej\relax }}{16}{figure.caption.16}}
\newlabel{fig:propagacjawsteczna}{{2.8}{16}{Algorytm propagacji wstecznej\relax }{figure.caption.16}{}}
\newlabel{eq:rprop}{{2.11}{16}{}{equation.2.3.11}{}}
\citation{pena2000evolutionary}
\citation{aforgenetgenetic}
\citation{montana1989training}
\citation{claypool1999combining}
\newlabel{ss:algorytm_genetyczny}{{2.3.4}{17}{}{subsubsection*.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Og\IeC {\'o}lny schemat algorytmu genetycznego\relax }}{17}{figure.caption.20}}
\newlabel{fig:algorytmgenetyczny}{{2.9}{17}{Ogólny schemat algorytmu genetycznego\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4\relax .\kern .5em }Algorytmy hybrydowe}{17}{section.2.4}}
\newlabel{s:algorytmyhybrydowe}{{2.4}{17}{}{section.2.4}{}}
\citation{adomavicius2005toward}
\citation{basu1998recommendation}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 3\relax .\kern .5em Algorytmy}{19}{section*.21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1\relax .\kern .5em }Model systemu}{19}{section.3.1}}
\citation{aforgenet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Model czarnoskrzynkowy\relax }}{20}{figure.caption.22}}
\newlabel{fig:blackbox}{{3.1}{20}{Model czarnoskrzynkowy\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Uog\IeC {\'o}lniony model elementu\relax }}{20}{figure.caption.23}}
\newlabel{fig:modelElementu}{{3.2}{20}{Uogólniony model elementu\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Uog\IeC {\'o}lniony model elementu\relax }}{20}{figure.caption.24}}
\newlabel{fig:modelUsera}{{3.3}{20}{Uogólniony model elementu\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2\relax .\kern .5em }Propozycja algorytmu filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci}{20}{section.3.2}}
\newlabel{s:propozycjaalgorytmucbf}{{3.2}{20}{}{section.3.2}{}}
\citation{aforgenet}
\citation{aforgenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1\relax .\kern .5em }Struktura perceptron\IeC {\'o}w i~funkcja aktywacji}{21}{subsection.3.2.1}}
\newlabel{sss:strukturaperceptronow}{{3.2.1}{21}{}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Schemat perceptronu\relax }}{21}{figure.caption.25}}
\newlabel{fig:schematneuronu}{{3.4}{21}{Schemat perceptronu\relax }{figure.caption.25}{}}
\newlabel{eq:neuroneq}{{3.1}{21}{}{equation.3.2.1}{}}
\newlabel{eq:sigmoidal}{{3.2}{21}{}{equation.3.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Wykres sigmoidalnej funkcji aktywacji perceptronu \cite {aforgenet}\relax }}{22}{figure.caption.26}}
\newlabel{fig:sigmoid}{{3.5}{22}{Wykres sigmoidalnej funkcji aktywacji perceptronu \protect \cite {aforgenet}\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2\relax .\kern .5em }Struktura sieci i~przebieg algorytmu}{22}{subsection.3.2.2}}
\newlabel{ss:strukturasiecineuronowej}{{3.2.2}{22}{}{subsection.3.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Schemat sieci neuronowej\relax }}{22}{figure.caption.27}}
\newlabel{fig:siecneuronowa}{{3.6}{22}{Schemat sieci neuronowej\relax }{figure.caption.27}{}}
\citation{osowski1996sieci}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Mapa cech elementu. Wiadomo, \IeC {\.z}e element X zawiera cech\IeC {\k e} ,,Aktor'' o~warto\IeC {\'s}ciach ,,Julia Roberts, Al Pacino'' oraz cech\IeC {\k e} ,,Re\IeC {\.z}yser'' o~warto\IeC {\'s}ci ,,Francis Ford Coppola''. Element nie zawiera cechy ,,Aktor'' o~warto\IeC {\'s}ci ,,Brad Pitt'' ani cechy ,,Re\IeC {\.z}yser'' o~warto\IeC {\'s}ci ,,Darren Aronofsky'' wi\IeC {\k e}c w~te miejsca wstawiane jest $0$.\relax }}{23}{figure.caption.28}}
\newlabel{fig:mapacech}{{3.7}{23}{Mapa cech elementu. Wiadomo, że element X zawiera cechę ,,Aktor'' o~wartościach ,,Julia Roberts, Al Pacino'' oraz cechę ,,Reżyser'' o~wartości ,,Francis Ford Coppola''. Element nie zawiera cechy ,,Aktor'' o~wartości ,,Brad Pitt'' ani cechy ,,Reżyser'' o~wartości ,,Darren Aronofsky'' więc w~te miejsca wstawiane jest $0$.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3\relax .\kern .5em }Uczenie sieci neuronowej}{23}{subsection.3.2.3}}
\newlabel{ss:uczeniesiecineuronowej}{{3.2.3}{23}{}{subsection.3.2.3}{}}
\newlabel{eq:weightadaptation}{{3.3}{23}{}{equation.3.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3\relax .\kern .5em }Propozycja nowych algorytm\IeC {\'o}w hybrydowych}{24}{section.3.3}}
\newlabel{eq:hybrid}{{3.4}{24}{}{equation.3.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Wp\IeC {\l }yw parametru $k$ na wynik algorytmu. Je\IeC {\.z}eli parametr $k=2$ a~uczenie sieci neuronowej zako\IeC {\'n}czy\IeC {\l }o si\IeC {\k e} z~b\IeC {\l }\IeC {\k e}dem r\IeC {\'o}wnym $d=1,2$, to ko\IeC {\'n}cowy stosunek wag wyniku filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci do wyniku filtrowania kolaboratywnego wyniesie ok. 43,5\% do 56,5\%.\relax }}{24}{figure.caption.29}}
\newlabel{fig:hybridfunction}{{3.8}{24}{Wpływ parametru $k$ na wynik algorytmu. Jeżeli parametr $k=2$ a~uczenie sieci neuronowej zakończyło się z~błędem równym $d=1,2$, to końcowy stosunek wag wyniku filtrowania z~analizą zawartości do wyniku filtrowania kolaboratywnego wyniesie ok. 43,5\% do 56,5\%.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1\relax .\kern .5em }Zalety zaproponowanych metod}{25}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2\relax .\kern .5em }Wady zaproponowanych metod}{26}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 4\relax .\kern .5em Badania eksperymentalne}{27}{section*.30}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1\relax .\kern .5em }Opis metody badawczej}{27}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}Przebieg eksperymentu}{27}{algorithm.5}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {5}Przebieg eksperymentu}{27}{algorithm.5}}
\newlabel{aq:experiment}{{5}{27}{}{algorithm.5}{}}
\citation{hyndman2006another}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1\relax .\kern .5em }Miara oceny}{28}{subsection.4.1.1}}
\newlabel{eq:rmse}{{4.1}{28}{}{equation.4.1.1}{}}
\citation{hyndman2006another}
\citation{harper2016movielens}
\citation{amazonmeta}
\citation{leskovec2007dynamics}
\newlabel{eq:mae}{{4.2}{29}{}{equation.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2\relax .\kern .5em }Zbiory danych}{29}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Schemat bazy MovieLens\relax }}{30}{figure.caption.34}}
\newlabel{fig:movielens_schema}{{4.1}{30}{Schemat bazy MovieLens\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2\relax .\kern .5em }\IeC {\'S}rodowisko symulacyjne}{30}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1\relax .\kern .5em }Oprogramowanie}{30}{subsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Zrzut ekranu \IeC {\'s}rodowiska symulacyjnego\relax }}{31}{figure.caption.36}}
\newlabel{fig:program}{{4.2}{31}{Zrzut ekranu środowiska symulacyjnego\relax }{figure.caption.36}{}}
\gdef \LT@i {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2\relax .\kern .5em }Sprz\IeC {\k e}t}{32}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3\relax .\kern .5em }Eksperymentalne dopasowanie parametr\IeC {\'o}w sieci neuronowej}{32}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1\relax .\kern .5em }Strojenie sieci dla bazy MovieLens}{32}{subsection.4.3.1}}
\newlabel{ss:strojeniemovielens}{{4.3.1}{32}{}{subsection.4.3.1}{}}
\newlabel{exp:expiterations}{{4.3.1}{32}{}{subsubsection*.37}{}}
\gdef \LT@ii {\LT@entry 
    {1}{59.25122pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{36.03738pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{81.70184pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Konfiguracja dla eksperymentu maksymalnej liczby iteracji\relax }}{33}{table.4.1}}
\newlabel{tab:expiterations}{{4.2}{33}{}{table.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu wyra\IeC {\.z}onego za pomoc\IeC {\k a} RMSE i~czasu wykonania od maksymalnej liczy iteracji (baza MovieLens).\relax }}{33}{table.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a~b\IeC {\l }\IeC {\k e}dem algorytmu wyra\IeC {\.z}onym za pomoc\IeC {\k a} RMSE (im ni\IeC {\.z}sza jego warto\IeC {\'s}\IeC {\'c} tym lepiej). Wraz ze wzrostem liczby iteracji warto\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du maleje, jednak\IeC {\.z}e po przekroczeniu pewnej warto\IeC {\'s}ci nast\IeC {\k e}puje ponowny wzrost. Wynika to z~wyst\IeC {\k e}powania zjawiska nadmiernego dopasowania (ang. \textit  {overfitting}). \relax }}{33}{figure.caption.38}}
\newlabel{fig:expiterations_rmse}{{4.3}{33}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zależność pomiędzy liczbą iteracji a~błędem algorytmu wyrażonym za pomocą RMSE (im niższa jego wartość tym lepiej). Wraz ze wzrostem liczby iteracji wartość błędu maleje, jednakże po przekroczeniu pewnej wartości następuje ponowny wzrost. Wynika to z~występowania zjawiska nadmiernego dopasowania (ang. \textit {overfitting}). \relax }{figure.caption.38}{}}
\gdef \LT@iii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a~czasem wykonania. Zgodnie z~oczekiwaniami, czas wykonania jest wprost proporcjonalny do liczby iteracji. W~trakcie tego eksperymentu potwierdzone zosta\IeC {\l }y r\IeC {\'o}wnie\IeC {\.z} przypuszczenia dotycz\IeC {\k a}ce pr\IeC {\k e}dko\IeC {\'s}ci dzia\IeC {\l }ania algorytm\IeC {\'o}w. Najszybszy okaza\IeC {\l } si\IeC {\k e} RPROP, jednak\IeC {\.z}e kosztem nieco wi\IeC {\k e}kszych b\IeC {\l }\IeC {\k e}d\IeC {\'o}w. Najgorzej wypad\IeC {\l } algorytm genetyczny, kt\IeC {\'o}ry charakteryzowa\IeC {\l } si\IeC {\k e} bardzo szybko rosn\IeC {\k a}cym czasem wykonania przy jednoczesnym nie najlepszym wynikiem RMSE. \relax }}{34}{figure.caption.39}}
\newlabel{fig:expiterations_time}{{4.4}{34}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie MovieLens. Wykres przedstawia zależność pomiędzy liczbą iteracji a~czasem wykonania. Zgodnie z~oczekiwaniami, czas wykonania jest wprost proporcjonalny do liczby iteracji. W~trakcie tego eksperymentu potwierdzone zostały również przypuszczenia dotyczące prędkości działania algorytmów. Najszybszy okazał się RPROP, jednakże kosztem nieco większych błędów. Najgorzej wypadł algorytm genetyczny, który charakteryzował się bardzo szybko rosnącym czasem wykonania przy jednoczesnym nie najlepszym wynikiem RMSE. \relax }{figure.caption.39}{}}
\newlabel{exp:momentum}{{4.3.1}{34}{}{subsubsection*.40}{}}
\gdef \LT@iv {\LT@entry 
    {1}{86.55678pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Konfiguracja dla eksperymentu dopasowania warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci\relax }}{35}{table.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymaln\IeC {\k a} warto\IeC {\'s}\IeC {\'c} wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy warto\IeC {\'s}ci\IeC {\k a} parametru a~b\IeC {\l }\IeC {\k e}dem RMSE. W~zakresie warto\IeC {\'s}ci $[0,0.9]$ b\IeC {\l }\IeC {\k a}d oscyluje w~granicach podobnych warto\IeC {\'s}ci z~nieznaczn\IeC {\k a} tendencj\IeC {\k a} malej\IeC {\k a}c\IeC {\k a}. Wyra\IeC {\'z}ny skok na niekorzy\IeC {\'s}\IeC {\'c} odnotowany jest dopiero przy momentum$=1$.\relax }}{35}{figure.caption.41}}
\newlabel{fig:expmomentum}{{4.5}{35}{Wyniki eksperymentu testującego optymalną wartość współczynnika bezwładności na bazie MovieLens. Wykres przedstawia zależność pomiędzy wartością parametru a~błędem RMSE. W~zakresie wartości $[0,0.9]$ błąd oscyluje w~granicach podobnych wartości z~nieznaczną tendencją malejącą. Wyraźny skok na niekorzyść odnotowany jest dopiero przy momentum$=1$.\relax }{figure.caption.41}{}}
\newlabel{tab:expmomentum}{{4.4}{35}{}{table.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci (baza MovieLens).\relax }}{35}{table.4.4}}
\gdef \LT@v {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\gdef \LT@vi {\LT@entry 
    {1}{76.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.12457pt}\LT@entry 
    {1}{0.0pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Konfiguracja dla eksperymentu dopasowania wielko\IeC {\'s}ci populacji\relax }}{36}{table.4.5}}
\newlabel{tab:exppopulation}{{4.6}{36}{}{table.4.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru populacji (baza MovieLens).\relax }}{36}{table.4.6}}
\gdef \LT@vii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar populacji na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem a~b\IeC {\l }\IeC {\k e}dem RMSE. Zgodnie z~oczekiwaniami wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem populacji a~czasem wykonania i~ujemna pomi\IeC {\k e}dzy rozmiarem populacji a~b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem populacji a~czasem wykonania jest liniowa, natomiast b\IeC {\l }\IeC {\k a}d maleje wyk\IeC {\l }adniczo gdy populacja osi\IeC {\k a}ga wi\IeC {\k e}ksze rozmiary. Optymalnym zatem jest przyj\IeC {\k e}cie rozmiaru populacji r\IeC {\'o}wnej $100$.\relax }}{37}{figure.caption.43}}
\newlabel{fig:exppopulation}{{4.6}{37}{Wyniki eksperymentu testującego optymalny rozmiar populacji na bazie MovieLens. Wykres przedstawia zależność pomiędzy rozmiarem a~błędem RMSE. Zgodnie z~oczekiwaniami występuje dodatnia korelacja pomiędzy rozmiarem populacji a~czasem wykonania i~ujemna pomiędzy rozmiarem populacji a~błędem algorytmu rekomendacji. Zależność pomiędzy rozmiarem populacji a~czasem wykonania jest liniowa, natomiast błąd maleje wykładniczo gdy populacja osiąga większe rozmiary. Optymalnym zatem jest przyjęcie rozmiaru populacji równej $100$.\relax }{figure.caption.43}{}}
\gdef \LT@viii {\LT@entry 
    {1}{92.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.5383pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w\relax }}{38}{table.4.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w na bazie MovieLens. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a~b\IeC {\l }\IeC {\k e}dem RMSE. Wyniki prezentuj\IeC {\k a} si\IeC {\k e} odmiennie w~zale\IeC {\.z}no\IeC {\'s}ci od typu algorytmu wykorzystanego do uczenia sieci. W~przypadku algorytm\IeC {\'o}w propagacji wstecznej i~RPROP wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem warstwy ukrytej a~b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Dla algorytmu RPROP optymalny rezultat osi\IeC {\k a}gni\IeC {\k e}ty zosta\IeC {\l } dla zaledwie jednego neuronu w~warstwie ukrytej, dla algorytmu BackProp dla pi\IeC {\k e}ciu neuron\IeC {\'o}w. W~tym ostatnim przypadku poprawa jest nieznaczna oscyluj\IeC {\k a}ca w~granicach 0,01. W~przypadku algorytmu genetycznego, niezale\IeC {\.z}nie od ilo\IeC {\'s}ci neuron\IeC {\'o}w wynik oscyluje na podobnym poziomie w~zakresie testowanych warto\IeC {\'s}ci.\relax }}{38}{figure.caption.45}}
\newlabel{fig:exphiddenneural}{{4.7}{38}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów na bazie MovieLens. Wykres przedstawia zależność pomiędzy ilością neuronów a~błędem RMSE. Wyniki prezentują się odmiennie w~zależności od typu algorytmu wykorzystanego do uczenia sieci. W~przypadku algorytmów propagacji wstecznej i~RPROP występuje dodatnia korelacja pomiędzy rozmiarem warstwy ukrytej a~błędem algorytmu rekomendacji. Dla algorytmu RPROP optymalny rezultat osiągnięty został dla zaledwie jednego neuronu w~warstwie ukrytej, dla algorytmu BackProp dla pięciu neuronów. W~tym ostatnim przypadku poprawa jest nieznaczna oscylująca w~granicach 0,01. W~przypadku algorytmu genetycznego, niezależnie od ilości neuronów wynik oscyluje na podobnym poziomie w~zakresie testowanych wartości.\relax }{figure.caption.45}{}}
\newlabel{tab:exphiddenneural}{{4.8}{38}{}{table.4.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru ukrytej warstwy neuronowej (baza MovieLens).\relax }}{38}{table.4.8}}
\gdef \LT@ix {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{251.85992pt}}
\gdef \LT@x {\LT@entry 
    {1}{59.25122pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.52457pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{81.70184pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w (baza MovieLens).\relax }}{39}{table.4.9}}
\newlabel{tab:optimummovielens}{{4.9}{39}{Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuronów (baza MovieLens).\relax }{table.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2\relax .\kern .5em }Strojenie sieci dla bazy AmazonMeta}{39}{subsection.4.3.2}}
\newlabel{ss:strojenieamazonmeta}{{4.3.2}{39}{}{subsection.4.3.2}{}}
\newlabel{tab:am_expiterations}{{4.10}{39}{}{table.4.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu wyra\IeC {\.z}onego za pomoc\IeC {\k a} RMSE i~czasu wykonania od maksymalnej liczy iteracji (baza AmazonMeta).\relax }}{39}{table.4.10}}
\gdef \LT@xi {\LT@entry 
    {1}{86.55678pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a~b\IeC {\l }\IeC {\k e}dem algorytmu wyra\IeC {\.z}onym za pomoc\IeC {\k a} RMSE. Pocz\IeC {\k a}tkowo warto\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du szybko maleje, jednak\IeC {\.z}e wraz ze wzrostem liczby iteracji k\IeC {\k a}ty nachylenia kolejnych odcink\IeC {\'o}w krzywej ulegaj\IeC {\k a} zwi\IeC {\k e}kszeniu. Bior\IeC {\k a}c pod uwag\IeC {\k e} rosn\IeC {\k a}cy liniowo czas wykonania (zob. \ref  {fig:am_expiterations_time}) w~pewnym momencie koszt w~postaci czasu wykonania przewy\IeC {\.z}sza korzy\IeC {\'s}\IeC {\'c} wynikaj\IeC {\k a}c\IeC {\k a} z~ni\IeC {\.z}szego b\IeC {\l }\IeC {\k e}du RMSE. W~zakresach liczby iteracji od 100 do 2000 wyst\IeC {\k e}puj\IeC {\k a} nieznaczne zachwiania, kt\IeC {\'o}re znajduj\IeC {\k a} si\IeC {\k e} w~zakresie b\IeC {\l }\IeC {\k e}du statystycznego. \relax }}{40}{figure.caption.48}}
\newlabel{fig:am_expiterations_rmse}{{4.8}{40}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy liczbą iteracji a~błędem algorytmu wyrażonym za pomocą RMSE. Początkowo wartość błędu szybko maleje, jednakże wraz ze wzrostem liczby iteracji kąty nachylenia kolejnych odcinków krzywej ulegają zwiększeniu. Biorąc pod uwagę rosnący liniowo czas wykonania (zob. \ref {fig:am_expiterations_time}) w~pewnym momencie koszt w~postaci czasu wykonania przewyższa korzyść wynikającą z~niższego błędu RMSE. W~zakresach liczby iteracji od 100 do 2000 występują nieznaczne zachwiania, które znajdują się w~zakresie błędu statystycznego. \relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a~czasem wykonania. Czas wykonania jest wprost proporcjonalny do liczby iteracji. \relax }}{40}{figure.caption.49}}
\newlabel{fig:am_expiterations_time}{{4.9}{40}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy liczbą iteracji a~czasem wykonania. Czas wykonania jest wprost proporcjonalny do liczby iteracji. \relax }{figure.caption.49}{}}
\newlabel{tab:am_expmomentum}{{4.11}{40}{}{table.4.11}{}}
\gdef \LT@xii {\LT@entry 
    {1}{76.06372pt}\LT@entry 
    {1}{62.01324pt}\LT@entry 
    {1}{52.87445pt}\LT@entry 
    {1}{0.0pt}}
\gdef \LT@xiii {\LT@entry 
    {1}{92.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.52457pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{52.87445pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci (baza AmazonMeta).\relax }}{41}{table.4.11}}
\newlabel{tab:am_exppopulation}{{4.12}{41}{}{table.4.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru populacji (baza AmazonMeta).\relax }}{41}{table.4.12}}
\newlabel{tab:am_exphiddenneural}{{4.13}{41}{}{table.4.13}{}}
\gdef \LT@xiv {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{267.58353pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE i~czasu wykonania od rozmiaru ukrytej warstwy neuronowej (baza AmazonMeta).\relax }}{42}{table.4.13}}
\@writefile{lot}{\contentsline {table}{\numberline {4.14}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w (baza AmazonMeta).\relax }}{42}{table.4.14}}
\newlabel{tab:am_optimummovielens}{{4.14}{42}{Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuronów (baza AmazonMeta).\relax }{table.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4\relax .\kern .5em }Eksperymentalne por\IeC {\'o}wnanie zaproponowanych algorytm\IeC {\'o}w hybrydowych z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci i~filtrowaniem kolaboratywnym}{42}{section.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymaln\IeC {\k a} warto\IeC {\'s}\IeC {\'c} wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy warto\IeC {\'s}ci\IeC {\k a} parametru a~b\IeC {\l }\IeC {\k e}dem RMSE. W~zakresie warto\IeC {\'s}ci $[0,0.9]$ b\IeC {\l }\IeC {\k a}d oscyluje w~granicach podobnych warto\IeC {\'s}ci z~nieznaczn\IeC {\k a} tendencj\IeC {\k a} malej\IeC {\k a}c\IeC {\k a}. Wyra\IeC {\'z}ny skok na niekorzy\IeC {\'s}\IeC {\'c} odnotowany jest dopiero przy momentum$=1$.\relax }}{43}{figure.caption.51}}
\newlabel{fig:am_expmomentum}{{4.10}{43}{Wyniki eksperymentu testującego optymalną wartość współczynnika bezwładności na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy wartością parametru a~błędem RMSE. W~zakresie wartości $[0,0.9]$ błąd oscyluje w~granicach podobnych wartości z~nieznaczną tendencją malejącą. Wyraźny skok na niekorzyść odnotowany jest dopiero przy momentum$=1$.\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar populacji na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem a~b\IeC {\l }\IeC {\k e}dem RMSE. Zgodnie z~oczekiwaniami wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem populacji a~czasem wykonania i~ujemna pomi\IeC {\k e}dzy rozmiarem populacji a~b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem populacji a~czasem wykonania jest liniowa, natomiast b\IeC {\l }\IeC {\k a}d maleje wyk\IeC {\l }adniczo gdy populacja osi\IeC {\k a}ga wi\IeC {\k e}ksze rozmiary. Optymalnym zatem jest przyj\IeC {\k e}cie rozmiaru populacji r\IeC {\'o}wnej $50$ tak, aby czas wykonania nie przekracza\IeC {\l } 200000ms.\relax }}{43}{figure.caption.53}}
\newlabel{fig:am_exppopulation}{{4.11}{43}{Wyniki eksperymentu testującego optymalny rozmiar populacji na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy rozmiarem a~błędem RMSE. Zgodnie z~oczekiwaniami występuje dodatnia korelacja pomiędzy rozmiarem populacji a~czasem wykonania i~ujemna pomiędzy rozmiarem populacji a~błędem algorytmu rekomendacji. Zależność pomiędzy rozmiarem populacji a~czasem wykonania jest liniowa, natomiast błąd maleje wykładniczo gdy populacja osiąga większe rozmiary. Optymalnym zatem jest przyjęcie rozmiaru populacji równej $50$ tak, aby czas wykonania nie przekraczał 200000ms.\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a~b\IeC {\l }\IeC {\k e}dem RMSE. W~przypadku algorytm\IeC {\'o}w propagacji wstecznej i~RPROP wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem warstwy ukrytej a~b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Dla algorytmu BackProp optymalne wyniki osi\IeC {\k a}gni\IeC {\k e}te zosta\IeC {\l }y dla zaledwie liczby neuron\IeC {\'o}w w~warstwie ukrytej nie przekraczaj\IeC {\k a}cej 5, dla algorytmu RPROP dla nie przekraczaj\IeC {\k a}cej 20. W~przypadku algorytmu genetycznego, niezale\IeC {\.z}nie od ilo\IeC {\'s}ci neuron\IeC {\'o}w wynik oscyluje na podobnym poziomie w~zakresie testowanych warto\IeC {\'s}ci.\relax }}{44}{figure.caption.55}}
\newlabel{fig:am_exphiddenneural_rmse}{{4.12}{44}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy ilością neuronów a~błędem RMSE. W~przypadku algorytmów propagacji wstecznej i~RPROP występuje dodatnia korelacja pomiędzy rozmiarem warstwy ukrytej a~błędem algorytmu rekomendacji. Dla algorytmu BackProp optymalne wyniki osiągnięte zostały dla zaledwie liczby neuronów w~warstwie ukrytej nie przekraczającej 5, dla algorytmu RPROP dla nie przekraczającej 20. W~przypadku algorytmu genetycznego, niezależnie od ilości neuronów wynik oscyluje na podobnym poziomie w~zakresie testowanych wartości.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w na bazie AmazonMeta. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a~czasem wykonania. Czas wykonania ro\IeC {\'s}nie liniowo proporcjonalnie do ilo\IeC {\'s}ci neuron\IeC {\'o}w. W~zwi\IeC {\k a}zku z~tym oraz bior\IeC {\k a}c pod uwag\IeC {\k e} wykres \ref  {fig:am_exphiddenneural_rmse} optymalnym jest ustalenie liczby neuron\IeC {\'o}w w~warstwie ukrytej na 1.\relax }}{44}{figure.caption.56}}
\newlabel{fig:am_exphiddenneural_time}{{4.13}{44}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów na bazie AmazonMeta. Wykres przedstawia zależność pomiędzy ilością neuronów a~czasem wykonania. Czas wykonania rośnie liniowo proporcjonalnie do ilości neuronów. W~związku z~tym oraz biorąc pod uwagę wykres \ref {fig:am_exphiddenneural_rmse} optymalnym jest ustalenie liczby neuronów w~warstwie ukrytej na 1.\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1\relax .\kern .5em }Badania na bazie MovieLens}{45}{subsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} propagacji wstecznej (baza MovieLens).\relax }}{45}{figure.caption.59}}
\newlabel{fig:ml_exphybrid1_1}{{4.14}{45}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą propagacji wstecznej (baza MovieLens).\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} propagacji wstecznej (baza MovieLens).\relax }}{46}{figure.caption.60}}
\newlabel{fig:ml_exphybrid1_2}{{4.15}{46}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą propagacji wstecznej (baza MovieLens).\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} propagacji wstecznej (baza MovieLens).\relax }}{46}{figure.caption.61}}
\newlabel{fig:ml_exphybrid1_3}{{4.16}{46}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą propagacji wstecznej (baza MovieLens).\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} RPROP (baza MovieLens).\relax }}{48}{figure.caption.62}}
\newlabel{fig:ml_exphybrid1_4}{{4.17}{48}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą RPROP (baza MovieLens).\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} RPROP (baza MovieLens).\relax }}{48}{figure.caption.63}}
\newlabel{fig:ml_exphybrid1_5}{{4.18}{48}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą RPROP (baza MovieLens).\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} RPROP (baza MovieLens).\relax }}{49}{figure.caption.64}}
\newlabel{fig:ml_exphybrid1_6}{{4.19}{49}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą RPROP (baza MovieLens).\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} algorytmem genetycznym'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} algorytmem genetycznym (baza MovieLens).\relax }}{49}{figure.caption.65}}
\newlabel{fig:ml_exphybrid1_7}{{4.20}{49}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą algorytmem genetycznym'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną algorytmem genetycznym (baza MovieLens).\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.21}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} algorytmem genetycznym (baza MovieLens).\relax }}{50}{figure.caption.66}}
\newlabel{fig:ml_exphybrid1_8}{{4.21}{50}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną algorytmem genetycznym (baza MovieLens).\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.22}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~algorytmem genetycznym'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} algorytmem genetycznym (baza MovieLens).\relax }}{50}{figure.caption.67}}
\newlabel{fig:ml_exphybrid1_9}{{4.22}{50}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą RPROP'' z~algorytmem genetycznym'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną algorytmem genetycznym (baza MovieLens).\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.23}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,matrix factorization''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,matrix factorization'' (baza MovieLens).\relax }}{51}{figure.caption.69}}
\newlabel{fig:ml_exphybrid2_1}{{4.23}{51}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem kolaboratywnym metodą ,,matrix factorization''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem kolaboratywnym metodą ,,matrix factorization'' (baza MovieLens).\relax }{figure.caption.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.24}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,matrix factorization''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,biased matrix factorization'' (baza MovieLens).\relax }}{52}{figure.caption.70}}
\newlabel{fig:ml_exphybrid2_2}{{4.24}{52}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metodą ,,matrix factorization''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem kolaboratywnym metodą ,,biased matrix factorization'' (baza MovieLens).\relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.25}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,biased matrix factorization''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,biased matrix factorization''(baza MovieLens).\relax }}{52}{figure.caption.71}}
\newlabel{fig:ml_exphybrid2_3}{{4.25}{52}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem kolaboratywnym metodą ,,biased matrix factorization''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metodą ,,biased matrix factorization''(baza MovieLens).\relax }{figure.caption.71}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.26}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,SVD++''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,SVD++'' (baza MovieLens).\relax }}{53}{figure.caption.72}}
\newlabel{fig:ml_exphybrid2_4}{{4.26}{53}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem kolaboratywnym metodą ,,SVD++''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem kolaboratywnym metodą ,,SVD++'' (baza MovieLens).\relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.27}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,SVD++'' (baza MovieLens).\relax }}{53}{figure.caption.73}}
\newlabel{fig:ml_exphybrid2_5}{{4.27}{53}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metodą ,,SVD++'' (baza MovieLens).\relax }{figure.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.28}{\ignorespaces Wykres przedstawia por\IeC {\'o}wnanie wynik\IeC {\'o}w dzia\IeC {\l }ania algorytm\IeC {\'o}w hybrydowych (s\IeC {\l }upki niebieskie) z~algorytmami filtrowania kolaboratywnego (s\IeC {\l }upki czarne) i~filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci (s\IeC {\l }upki szare) (baza MovieLens).\relax }}{54}{figure.caption.75}}
\newlabel{fig:ml_exphybrid}{{4.28}{54}{Wykres przedstawia porównanie wyników działania algorytmów hybrydowych (słupki niebieskie) z~algorytmami filtrowania kolaboratywnego (słupki czarne) i~filtrowania z~analizą zawartości (słupki szare) (baza MovieLens).\relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2\relax .\kern .5em }Badania na bazie AmazonMeta}{55}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.29}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} propagacji wstecznej. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} propagacji wstecznej (baza AmazonMeta).\relax }}{56}{figure.caption.78}}
\newlabel{fig:am_exphybrid1_1}{{4.29}{56}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą propagacji wstecznej. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą propagacji wstecznej (baza AmazonMeta).\relax }{figure.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.30}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} propagacji wstecznej. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} RPROP (baza AmazonMeta).\relax }}{56}{figure.caption.79}}
\newlabel{fig:am_exphybrid1_2}{{4.30}{56}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,SVD++ i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą propagacji wstecznej. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą RPROP (baza AmazonMeta).\relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.31}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} RPROP. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} metod\IeC {\k a} RPROP (baza AmazonMeta).\relax }}{57}{figure.caption.80}}
\newlabel{fig:am_exphybrid1_3}{{4.31}{57}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą RPROP. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną metodą RPROP (baza AmazonMeta).\relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.32}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} algorytmem genetycznym. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} algorytmem genetycznym (baza AmazonMeta).\relax }}{57}{figure.caption.81}}
\newlabel{fig:am_exphybrid1_4}{{4.32}{57}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną algorytmem genetycznym. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną algorytmem genetycznym (baza AmazonMeta).\relax }{figure.caption.81}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.33}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analiz\IeC {\k a} zawarto\IeC {\'s}ci z~sieci\IeC {\k a} neuronow\IeC {\k a} uczon\IeC {\k a} algorytmem genetycznym (baza AmazonMeta).\relax }}{58}{figure.caption.82}}
\newlabel{fig:am_exphybrid1_5}{{4.33}{58}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem z~analizą zawartości z~siecią neuronową uczoną algorytmem genetycznym (baza AmazonMeta).\relax }{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.34}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,matrix factorization''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,matrix factorization'' (baza AmazonMeta).\relax }}{58}{figure.caption.83}}
\newlabel{fig:am_exphybrid2_1}{{4.34}{58}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem kolaboratywnym metodą ,,matrix factorization''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem kolaboratywnym metodą ,,matrix factorization'' (baza AmazonMeta).\relax }{figure.caption.83}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.35}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,matrix factorization''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,biased matrix factorization'' (baza AmazonMeta).\relax }}{59}{figure.caption.84}}
\newlabel{fig:am_exphybrid2_2}{{4.35}{59}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metodą ,,matrix factorization''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem kolaboratywnym metodą ,,biased matrix factorization'' (baza AmazonMeta).\relax }{figure.caption.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.36}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,biased matrix factorization''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,biased matrix factorization i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,biased matrix factorization''(baza AmazonMeta).\relax }}{59}{figure.caption.85}}
\newlabel{fig:am_exphybrid2_3}{{4.36}{59}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem kolaboratywnym metodą ,,biased matrix factorization''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,biased matrix factorization i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metodą ,,biased matrix factorization''(baza AmazonMeta).\relax }{figure.caption.85}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.37}{\ignorespaces \textbf  {Po lewej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} propagacji wstecznej'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,SVD++''. \textbf  {Po prawej}: wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona metod\IeC {\k a} RPROP'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,SVD++'' (baza AmazonMeta).\relax }}{60}{figure.caption.86}}
\newlabel{fig:am_exphybrid2_4}{{4.37}{60}{\textbf {Po lewej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą propagacji wstecznej'' z~filtrowaniem kolaboratywnym metodą ,,SVD++''. \textbf {Po prawej}: wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona metodą RPROP'' z~filtrowaniem kolaboratywnym metodą ,,SVD++'' (baza AmazonMeta).\relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.38}{\ignorespaces Wyniki eksperymentu por\IeC {\'o}wnuj\IeC {\k a}cego dzia\IeC {\l }anie algorytmu hybrydowego ,,SVD++ i~sie\IeC {\'c} neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metod\IeC {\k a} ,,SVD++'' (baza MovieLens).\relax }}{60}{figure.caption.87}}
\newlabel{fig:am_exphybrid2_5}{{4.38}{60}{Wyniki eksperymentu porównującego działanie algorytmu hybrydowego ,,SVD++ i~sieć neuronowa uczona algorytmem genetycznym'' z~filtrowaniem kolaboratywnym metodą ,,SVD++'' (baza MovieLens).\relax }{figure.caption.87}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.39}{\ignorespaces Wykres przedstawia por\IeC {\'o}wnanie wynik\IeC {\'o}w dzia\IeC {\l }ania algorytm\IeC {\'o}w hybrydowych (s\IeC {\l }upki niebieskie) z~algorytmami filtrowania kolaboratywnego (s\IeC {\l }upki czarne) i~filtrowania z~analiz\IeC {\k a} zawarto\IeC {\'s}ci (s\IeC {\l }upki szare) (baza AmazonMeta).\relax }}{61}{figure.caption.89}}
\newlabel{fig:am_exphybrid}{{4.39}{61}{Wykres przedstawia porównanie wyników działania algorytmów hybrydowych (słupki niebieskie) z~algorytmami filtrowania kolaboratywnego (słupki czarne) i~filtrowania z~analizą zawartości (słupki szare) (baza AmazonMeta).\relax }{figure.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.40}{\ignorespaces Podsumowanie analizy metod\IeC {\k a} ANOVA Friedmana na poziomie istotno\IeC {\'s}ci 0,05 (baza AmazonMeta).\relax }}{62}{figure.caption.91}}
\newlabel{fig:friedman2}{{4.40}{62}{Podsumowanie analizy metodą ANOVA Friedmana na poziomie istotności 0,05 (baza AmazonMeta).\relax }{figure.caption.91}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3\relax .\kern .5em }Podsumowanie}{62}{subsection.4.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.41}{\ignorespaces Analiza POST-HOC metod\IeC {\k a} Dunna. Pierwsze 9 kolumn i wierszy reprezentuje algorytmy hybrydowe, nast\IeC {\k e}pne 3 algorytmy filtrowania kolaboratywnego, ostatnie 3 algorytmy filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci (baza AmazonMeta).\relax }}{63}{figure.caption.92}}
\newlabel{fig:friedman1}{{4.41}{63}{Analiza POST-HOC metodą Dunna. Pierwsze 9 kolumn i wierszy reprezentuje algorytmy hybrydowe, następne 3 algorytmy filtrowania kolaboratywnego, ostatnie 3 algorytmy filtrowania z analizą zawartości (baza AmazonMeta).\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 5\relax .\kern .5em Wnioski}{65}{section*.93}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{iisthesis}
\bibdata{bibliography}
\bibcite{id:mgp}{1}
\bibcite{adomavicius2005toward}{2}
\bibcite{id:allegrofaq}{3}
\bibcite{amazonmeta}{4}
\bibcite{effandpractstochsub}{5}
\bibcite{basu1998recommendation}{6}
\bibcite{bell2007modeling}{7}
\bibcite{bottou2012stochastic}{8}
\bibcite{id:celma2010music}{9}
\bibcite{id:NewRecommentationAlgoritmBasedOnSocialNetwork}{10}
\bibcite{claypool1999combining}{11}
\bibcite{id:TheYouTubeVideoRecommendationSystem}{12}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{67}{section*.95}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{id:ComprehensiveSurveyOfNeighborhoodBasedRecommendationMethods}{13}
\bibcite{id:filmwebfaq}{14}
\bibcite{mymedialite}{15}
\bibcite{gantner2011mymedialite}{16}
\bibcite{id:gupta2013wtf}{17}
\bibcite{harper2016movielens}{18}
\bibcite{haykin1994neural}{19}
\bibcite{hertz1993wstkep}{20}
\bibcite{id:FromTapestryToSVD}{21}
\bibcite{id:huynh2012modeling}{22}
\bibcite{hyndman2006another}{23}
\bibcite{id:imdbstats}{24}
\bibcite{id:NextSongRecommendationWithTemporalDynamics}{25}
\bibcite{aforgenet}{26}
\bibcite{aforgenetgenetic}{27}
\bibcite{koren2008factorization}{28}
\bibcite{koren2010factor}{29}
\bibcite{id:AdvancesInCollaborativeFiltering}{30}
\bibcite{koren2009matrix}{31}
\bibcite{kwateralgorytmy}{32}
\bibcite{lemire2005slope}{33}
\bibcite{leskovec2007dynamics}{34}
\bibcite{id:linden2003amazon}{35}
\bibcite{id:ContentBasedRecommenderSystemsState}{36}
\bibcite{id:MaleszkaMianowskaNguyenmethod}{37}
\bibcite{melville2002content}{38}
\bibcite{montana1989training}{39}
\bibcite{mymedialitedatasets}{40}
\bibcite{id:NetflixPrize}{41}
\bibcite{id:NetflixPrize2}{42}
\bibcite{id:NetflixPrizeRankings}{43}
\bibcite{id:NetflixPrizeRules}{44}
\bibcite{osowski1996sieci}{45}
\bibcite{pariser2011filter}{46}
\bibcite{pena2000evolutionary}{47}
\bibcite{id:aStreamOfMovies}{48}
\bibcite{rendle2008online}{49}
\bibcite{id:IntroductionToRecommenderSystemsHandbook}{50}
\bibcite{riedmiller1993direct}{51}
\bibcite{riedmiller1994rprop}{52}
\bibcite{id:ComputingRecommendationsExtremeScaleApacheFlink}{53}
\bibcite{id:RubensRecSysHB2010}{54}
\bibcite{salakhutdinov2011probabilistic}{55}
\bibcite{sarwar2000application}{56}
\bibcite{id:CollaborativeFilteringRecommenderSystems}{57}
\bibcite{id:EvolutionOfRecommenderSystems}{58}
\bibcite{timothy1996sieci}{59}
\bibcite{willmott2005advantages}{60}
\bibcite{yahoomusicwebsite}{61}
\bibcite{id:zhang2015hybrid}{62}
