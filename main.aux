\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{*}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\@writefile{toc}{\contentsline {chapter}{Todo list}{1}{section*.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{id:FromTapestryToSVD}
\citation{id:EvolutionOfRecommenderSystems}
\citation{id:NetflixPrize}
\citation{id:NetflixPrizeRankings}
\citation{id:NetflixPrize2}
\citation{id:NetflixPrizeRules}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 1\relax .\kern .5em Wst\IeC {\k e}p}{3}{section*.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (P\IeC {\'O}\IeC {\'Z}NIEJ) CEL PRACY: trzeba rozszerzy\IeC {\'c} opis, w szczeg\IeC {\'o}lno\IeC {\'s}ci o to, co jest nowego i czym r\IeC {\'o}\IeC {\.z}ni si\IeC {\k e} od innych ju\IeC {\.z} istniej\IeC {\k a}cych algorytm\IeC {\'o}w}{4}{section*.4}}
\pgfsyspdfmark {pgfid1}{5816759}{42620499}
\pgfsyspdfmark {pgfid2}{2120848}{42637429}
\pgfsyspdfmark {pgfid3}{3787442}{42366547}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (P\IeC {\'O}\IeC {\'Z}NIEJ) streszczenie spisu tre\IeC {\'s}ci}{4}{section*.5}}
\pgfsyspdfmark {pgfid6}{5816759}{38819411}
\pgfsyspdfmark {pgfid7}{2120848}{35647625}
\pgfsyspdfmark {pgfid8}{3787442}{35376743}
\citation{id:TheYouTubeVideoRecommendationSystem}
\citation{id:mgp}
\citation{id:aStreamOfMovies}
\citation{id:filmwebfaq}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 2\relax .\kern .5em Przegl\IeC {\k a}d istniej\IeC {\k a}cych rozwi\IeC {\k a}za\IeC {\'n}}{5}{section*.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.1\relax .\kern .5em }Rekomendacja muzyki}{5}{subsection.2.0.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.2\relax .\kern .5em }Rekomendacja film\IeC {\'o}w}{5}{subsection.2.0.2}}
\citation{id:imdbstats}
\citation{id:allegrofaq}
\citation{id:linden2003amazon}
\citation{id:IntroductionToRecommenderSystemsHandbook}
\citation{id:IntroductionToRecommenderSystemsHandbook}
\citation{id:CollaborativeFilteringRecommenderSystems}
\citation{id:huynh2012modeling}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.0.3\relax .\kern .5em }Platformy typu e-commerce}{6}{subsection.2.0.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1\relax .\kern .5em }Techniki rekomendacji}{6}{section.2.1}}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{koren2009matrix}
\citation{id:ComprehensiveSurveyOfNeighborhoodBasedRecommendationMethods}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{koren2009matrix}
\citation{melville2002content}
\@writefile{toc}{\contentsline {section}{\numberline {2.2\relax .\kern .5em }Filtrowanie kolaboratywne}{7}{section.2.2}}
\newlabel{s:filtrowaniekolaboratywne}{{2.2}{7}{}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Filtrowanie kolaboratywne metod\IeC {\k a} s\IeC {\k a}siedztwa, zorientowane na u\IeC {\.z}ytkownika \cite {koren2009matrix}.\relax }}{7}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cf}{{2.1}{7}{Filtrowanie kolaboratywne metodą sąsiedztwa, zorientowane na użytkownika \protect \cite {koren2009matrix}.\relax }{figure.caption.7}{}}
\citation{pariser2011filter}
\citation{id:NewRecommentationAlgoritmBasedOnSocialNetwork}
\citation{id:NextSongRecommendationWithTemporalDynamics}
\citation{koren2009matrix}
\citation{id:RubensRecSysHB2010}
\citation{id:zhang2015hybrid}
\citation{id:celma2010music}
\citation{id:RubensRecSysHB2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Filtrowanie kolaboratywne z wykorzystaniem modelu ukrytych parametr\IeC {\'o}w \cite {koren2009matrix}.\relax }}{8}{figure.caption.8}}
\newlabel{fig:cf2}{{2.2}{8}{Filtrowanie kolaboratywne z wykorzystaniem modelu ukrytych parametrów \protect \cite {koren2009matrix}.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1\relax .\kern .5em }Zalety filtrowania kolaboratywnego}{8}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2\relax .\kern .5em }Wady filtrowania kolaboratywnego}{8}{subsection.2.2.2}}
\citation{id:RubensRecSysHB2010}
\citation{id:RubensRecSysHB2010}
\citation{id:gupta2013wtf}
\citation{mymedialite}
\citation{gantner2011mymedialite}
\citation{koren2008factorization}
\citation{salakhutdinov2011probabilistic}
\citation{rendle2008online}
\citation{bell2007modeling}
\citation{lemire2005slope}
\citation{koren2010factor}
\citation{mymedialitedatasets}
\citation{mymedialitedatasets}
\citation{harper2016movielens}
\citation{id:ComputingRecommendationsExtremeScaleApacheFlink}
\citation{id:ComputingRecommendationsExtremeScaleApacheFlink}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Problem d\IeC {\l }ugiego ogona: 50\% ocen dotyczy 10-12\% najpopularniejszych element\IeC {\'o}w w systemie \cite {id:RubensRecSysHB2010}.\relax }}{9}{figure.caption.9}}
\newlabel{fig:longtail}{{2.3}{9}{Problem długiego ogona: 50\% ocen dotyczy 10-12\% najpopularniejszych elementów w systemie \protect \cite {id:RubensRecSysHB2010}.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3\relax .\kern .5em }Algorytmy filtrowania kolaboratywnego}{9}{subsection.2.2.3}}
\citation{koren2009matrix}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Test algorytm\IeC {\'o}w filtrowania kolaboratywnego \cite {mymedialitedatasets}\relax }}{10}{figure.caption.10}}
\newlabel{fig:cfcomparision}{{2.4}{10}{Test algorytmów filtrowania kolaboratywnego \protect \cite {mymedialitedatasets}\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Faktoryzacja macierzy \cite {id:ComputingRecommendationsExtremeScaleApacheFlink}\relax }}{10}{figure.caption.12}}
\newlabel{fig:factorization}{{2.5}{10}{Faktoryzacja macierzy \protect \cite {id:ComputingRecommendationsExtremeScaleApacheFlink}\relax }{figure.caption.12}{}}
\citation{bottou2012stochastic}
\citation{effandpractstochsub}
\citation{effandpractstochsub}
\newlabel{eq:sgd1}{{2.1}{11}{}{equation.2.2.1}{}}
\newlabel{eq:sgd2}{{2.2}{11}{}{equation.2.2.2}{}}
\newlabel{eq:sgd3}{{2.3}{11}{}{equation.2.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}Stochastyczny gradient prosty}{11}{algorithm.1}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {1}Stochastyczny gradient prosty}{11}{algorithm.1}}
\newlabel{aq:sgd}{{1}{11}{}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces R\IeC {\'o}\IeC {\.z}nica pomi\IeC {\k e}dzy klasycznym gradientem prostym (po lewej) a jego stochastyczn\IeC {\k a} wersj\IeC {\k a} (po prawej) \cite {effandpractstochsub}\relax }}{12}{figure.caption.14}}
\newlabel{fig:sgd}{{2.6}{12}{Różnica pomiędzy klasycznym gradientem prostym (po lewej) a jego stochastyczną wersją (po prawej) \protect \cite {effandpractstochsub}\relax }{figure.caption.14}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}Matrix Factorization -- Inicjacja modelu}{12}{algorithm.2}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {2}Matrix Factorization -- Inicjacja modelu}{12}{algorithm.2}}
\newlabel{aq:mf_init}{{2}{12}{}{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}Matrix Factorization -- Faza uczenia}{13}{algorithm.3}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {3}Matrix Factorization -- Faza uczenia}{13}{algorithm.3}}
\newlabel{aq:mf_learn}{{3}{13}{}{algorithm.3}{}}
\newlabel{eq:global_bias}{{2.4}{13}{}{equation.2.2.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}Biased Matrix Factorization -- Faza uczenia}{14}{algorithm.4}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {4}Biased Matrix Factorization -- Faza uczenia}{14}{algorithm.4}}
\newlabel{aq:bmf_learn}{{4}{14}{}{algorithm.4}{}}
\newlabel{eq:svd}{{2.5}{14}{}{equation.2.2.5}{}}
\citation{koren2008factorization}
\citation{id:huynh2012modeling}
\citation{id:ContentBasedRecommenderSystemsState}
\citation{id:MaleszkaMianowskaNguyenmethod}
\citation{id:ContentBasedRecommenderSystemsState}
\citation{id:AdvancesInCollaborativeFiltering}
\citation{id:ContentBasedRecommenderSystemsState}
\@writefile{toc}{\contentsline {section}{\numberline {2.3\relax .\kern .5em }Filtrowanie z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{15}{section.2.3}}
\newlabel{s:filtrowaniezanalizazawartosci}{{2.3}{15}{}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1\relax .\kern .5em }Zalety filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{15}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2\relax .\kern .5em }Wady filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{15}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3\relax .\kern .5em }Metody tworzenia profilu u\IeC {\.z}ytkownika}{15}{subsection.2.3.3}}
\newlabel{ss:metody_tworzenia_profilu_uzytkownika}{{2.3.3}{15}{}{subsection.2.3.3}{}}
\citation{kwateralgorytmy}
\citation{kwateralgorytmy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4\relax .\kern .5em }Algorytmy wykorzystywane w implementacji filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{16}{subsection.2.3.4}}
\newlabel{sss:backprop}{{2.3.4}{16}{}{subsubsection*.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Algorytm propagacji wstecznej w sieci tr\IeC {\'o}jwarstwowej -- idea dzia\IeC {\l }ania \cite {kwateralgorytmy}\relax }}{16}{figure.caption.19}}
\newlabel{fig:ilustracjabackprop}{{2.7}{16}{Algorytm propagacji wstecznej w sieci trójwarstwowej -- idea działania \protect \cite {kwateralgorytmy}\relax }{figure.caption.19}{}}
\newlabel{eq:weightadaptation3}{{2.6}{16}{}{equation.2.3.6}{}}
\newlabel{eq:weightadaptation2}{{2.7}{16}{}{equation.2.3.7}{}}
\citation{haykin1994neural}
\citation{hertz1993wstkep}
\citation{kwateralgorytmy}
\citation{osowski1996sieci}
\citation{timothy1996sieci}
\newlabel{eq:weightadaptation4}{{2.8}{17}{}{equation.2.3.8}{}}
\newlabel{sss:metoda_momentum}{{2.3.4}{17}{}{subsubsection*.21}{}}
\newlabel{eq:zasadamomentum1}{{2.9}{17}{}{equation.2.3.9}{}}
\newlabel{eq:zasadamomentum2}{{2.10}{17}{}{equation.2.3.10}{}}
\citation{riedmiller1993direct}
\citation{riedmiller1994rprop}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Algorytm propagacji wstecznej\relax }}{18}{figure.caption.20}}
\newlabel{fig:propagacjawsteczna}{{2.8}{18}{Algorytm propagacji wstecznej\relax }{figure.caption.20}{}}
\newlabel{eq:rprop}{{2.11}{18}{}{equation.2.3.11}{}}
\citation{pena2000evolutionary}
\citation{aforgenetgenetic}
\citation{montana1989training}
\citation{claypool1999combining}
\newlabel{ss:algorytm_genetyczny}{{2.3.4}{19}{}{subsubsection*.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Og\IeC {\'o}lny schemat algorytmu genetycznego\relax }}{19}{figure.caption.24}}
\newlabel{fig:algorytmgenetyczny}{{2.9}{19}{Ogólny schemat algorytmu genetycznego\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4\relax .\kern .5em }Algorytmy hybrydowe}{19}{section.2.4}}
\newlabel{s:algorytmyhybrydowe}{{2.4}{19}{}{section.2.4}{}}
\citation{adomavicius2005toward}
\citation{basu1998recommendation}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 3\relax .\kern .5em Algorytmy}{21}{section*.25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1\relax .\kern .5em }Model systemu}{21}{section.3.1}}
\citation{aforgenet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Model czarnoskrzynkowy\relax }}{22}{figure.caption.26}}
\newlabel{fig:blackbox}{{3.1}{22}{Model czarnoskrzynkowy\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Uog\IeC {\'o}lniony model elementu\relax }}{22}{figure.caption.27}}
\newlabel{fig:modelElementu}{{3.2}{22}{Uogólniony model elementu\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Uog\IeC {\'o}lniony model elementu\relax }}{22}{figure.caption.28}}
\newlabel{fig:modelUsera}{{3.3}{22}{Uogólniony model elementu\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2\relax .\kern .5em }Propozycja algorytmu filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci}{22}{section.3.2}}
\newlabel{s:propozycjaalgorytmucbf}{{3.2}{22}{}{section.3.2}{}}
\citation{aforgenet}
\citation{aforgenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1\relax .\kern .5em }Struktura perceptron\IeC {\'o}w i funkcja aktywacji}{23}{subsection.3.2.1}}
\newlabel{sss:strukturaperceptronow}{{3.2.1}{23}{}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Schemat perceptronu\relax }}{23}{figure.caption.29}}
\newlabel{fig:schematneuronu}{{3.4}{23}{Schemat perceptronu\relax }{figure.caption.29}{}}
\newlabel{eq:neuroneq}{{3.1}{23}{}{equation.3.2.1}{}}
\newlabel{eq:sigmoidal}{{3.2}{23}{}{equation.3.2.2}{}}
\citation{osowski1996sieci}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Wykres sigmoidalnej funkcji aktywacji perceptronu \cite {aforgenet}\relax }}{24}{figure.caption.30}}
\newlabel{fig:sigmoid}{{3.5}{24}{Wykres sigmoidalnej funkcji aktywacji perceptronu \protect \cite {aforgenet}\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2\relax .\kern .5em }Struktura sieci i przebieg algorytmu}{24}{subsection.3.2.2}}
\newlabel{ss:strukturasiecineuronowej}{{3.2.2}{24}{}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3\relax .\kern .5em }Uczenie sieci neuronowej}{24}{subsection.3.2.3}}
\newlabel{ss:uczeniesiecineuronowej}{{3.2.3}{24}{}{subsection.3.2.3}{}}
\newlabel{eq:weightadaptation}{{3.3}{24}{}{equation.3.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Schemat sieci neuronowej\relax }}{25}{figure.caption.31}}
\newlabel{fig:siecneuronowa}{{3.6}{25}{Schemat sieci neuronowej\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Mapa cech elementu. Wiadomo, \IeC {\.z}e element X zawiera cech\IeC {\k e} ,,Aktor'' o warto\IeC {\'s}ciach ,,Julia Roberts, Al Pacino'' oraz cech\IeC {\k e} ,,Re\IeC {\.z}yser'' o warto\IeC {\'s}ci ,,Francis Ford Coppola''. Element nie zawiera cechy ,,Aktor'' o warto\IeC {\'s}ci ,,Brad Pitt'' ani cechy ,,Re\IeC {\.z}yser'' o warto\IeC {\'s}ci ,,Darren Aronofsky'' wi\IeC {\k e}c w te miejsca wstawiane jest $0$.\relax }}{25}{figure.caption.32}}
\newlabel{fig:mapacech}{{3.7}{25}{Mapa cech elementu. Wiadomo, że element X zawiera cechę ,,Aktor'' o wartościach ,,Julia Roberts, Al Pacino'' oraz cechę ,,Reżyser'' o wartości ,,Francis Ford Coppola''. Element nie zawiera cechy ,,Aktor'' o wartości ,,Brad Pitt'' ani cechy ,,Reżyser'' o wartości ,,Darren Aronofsky'' więc w te miejsca wstawiane jest $0$.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3\relax .\kern .5em }Propozycja nowych algorytm\IeC {\'o}w hybrydowych}{26}{section.3.3}}
\newlabel{eq:hybrid}{{3.4}{26}{}{equation.3.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Wp\IeC {\l }yw parametru $k$ na wynik algorytmu. Je\IeC {\.z}eli parametr $k=2$ a uczenie sieci neuronowej zako\IeC {\'n}czy\IeC {\l }o si\IeC {\k e} z b\IeC {\l }\IeC {\k e}dem r\IeC {\'o}wnym $d=1,2$, to ko\IeC {\'n}cowy stosunek wag wyniku filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci do wyniku filtrowania kolaboratywnego wyniesie ok. 43,5\% do 56,5\%.\relax }}{26}{figure.caption.33}}
\newlabel{fig:hybridfunction}{{3.8}{26}{Wpływ parametru $k$ na wynik algorytmu. Jeżeli parametr $k=2$ a uczenie sieci neuronowej zakończyło się z błędem równym $d=1,2$, to końcowy stosunek wag wyniku filtrowania z analizą zawartości do wyniku filtrowania kolaboratywnego wyniesie ok. 43,5\% do 56,5\%.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1\relax .\kern .5em }Zalety zaproponowanych metod}{27}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2\relax .\kern .5em }Wady zaproponowanych metod}{28}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 4\relax .\kern .5em Ocena eksperymentalna}{29}{section*.34}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1\relax .\kern .5em }Opis metody badawczej}{29}{section.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}Przebieg eksperymentu}{29}{algorithm.5}}
\@writefile{algo}{\contentsline {myalgorithm}{\numberline {5}Przebieg eksperymentu}{29}{algorithm.5}}
\newlabel{aq:experiment}{{5}{29}{}{algorithm.5}{}}
\citation{hyndman2006another}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1\relax .\kern .5em }Miara oceny}{30}{subsection.4.1.1}}
\newlabel{eq:rmse}{{4.1}{30}{}{equation.4.1.1}{}}
\citation{hyndman2006another}
\citation{harper2016movielens}
\citation{yahoomusicwebsite}
\newlabel{eq:mae}{{4.2}{31}{}{equation.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2\relax .\kern .5em }Zbiory danych}{31}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Schemat bazy MovieLens\relax }}{32}{figure.caption.38}}
\newlabel{fig:movielens_schema}{{4.1}{32}{Schemat bazy MovieLens\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2\relax .\kern .5em }\IeC {\'S}rodowisko symulacyjne}{32}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1\relax .\kern .5em }Oprogramowanie}{32}{subsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Zrzut ekranu \IeC {\'s}rodowiska symulacyjnego\relax }}{33}{figure.caption.40}}
\newlabel{fig:program}{{4.2}{33}{Zrzut ekranu środowiska symulacyjnego\relax }{figure.caption.40}{}}
\gdef \LT@i {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2\relax .\kern .5em }Sprz\IeC {\k e}t}{34}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3\relax .\kern .5em }Przeprowadzone eksperymenty}{34}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1\relax .\kern .5em }Dopasowanie parametr\IeC {\'o}w sieci neuronowej}{34}{subsection.4.3.1}}
\newlabel{exp:expiterations}{{4.3.1}{34}{}{subsubsection*.41}{}}
\gdef \LT@ii {\LT@entry 
    {1}{59.25122pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{36.03738pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{81.70184pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Konfiguracja dla eksperymentu maksymalnej liczby iteracji\relax }}{35}{table.4.1}}
\newlabel{tab:expiterations}{{4.2}{35}{}{table.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu wyra\IeC {\.z}onego za pomoc\IeC {\k a} RMSE i czasu wykonania od maksymalnej liczy iteracji.\relax }}{35}{table.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a b\IeC {\l }\IeC {\k e}dem algorytmu wyra\IeC {\.z}onym za pomoc\IeC {\k a} RMSE. Wraz ze wzrostem liczby iteracji warto\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du maleje, jednak\IeC {\.z}e po przekroczeniu pewnej warto\IeC {\'s}ci nast\IeC {\k e}puje ponowny wzrost. Wynika to z wyst\IeC {\k e}powania zjawiska nadmiernego dopasowania (ang. \textit  {overfitting}). \relax }}{35}{figure.caption.42}}
\newlabel{fig:expiterations_rmse}{{4.3}{35}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji. Wykres przedstawia zależność pomiędzy liczbą iteracji a błędem algorytmu wyrażonym za pomocą RMSE. Wraz ze wzrostem liczby iteracji wartość błędu maleje, jednakże po przekroczeniu pewnej wartości następuje ponowny wzrost. Wynika to z występowania zjawiska nadmiernego dopasowania (ang. \textit {overfitting}). \relax }{figure.caption.42}{}}
\gdef \LT@iii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego parametr maksymalnej liczby iteracji. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy liczb\IeC {\k a} iteracji a czasem wykonania. Zgodnie z oczekiwaniami, czas wykonania jest wprost proporcjonalny do liczby iteracji. W trakcie tego eksperymentu potwierdzone zosta\IeC {\l }y r\IeC {\'o}wnie\IeC {\.z} przypuszczenia dotycz\IeC {\k a}ce pr\IeC {\k e}dko\IeC {\'s}ci dzia\IeC {\l }ania algorytm\IeC {\'o}w. Najszybszy okaza\IeC {\l } si\IeC {\k e} RPROP, jednak\IeC {\.z}e kosztem nieco wi\IeC {\k e}kszych b\IeC {\l }\IeC {\k e}d\IeC {\'o}w. Najgorzej wypad\IeC {\l } algorytm genetyczny, kt\IeC {\'o}ry charakteryzowa\IeC {\l } si\IeC {\k e} bardzo szybko rosn\IeC {\k a}cym czasem wykonania przy jednoczesnym nie najlepszym wynikiem RMSE. \relax }}{36}{figure.caption.43}}
\newlabel{fig:expiterations_time}{{4.4}{36}{Wyniki eksperymentu testującego parametr maksymalnej liczby iteracji. Wykres przedstawia zależność pomiędzy liczbą iteracji a czasem wykonania. Zgodnie z oczekiwaniami, czas wykonania jest wprost proporcjonalny do liczby iteracji. W trakcie tego eksperymentu potwierdzone zostały również przypuszczenia dotyczące prędkości działania algorytmów. Najszybszy okazał się RPROP, jednakże kosztem nieco większych błędów. Najgorzej wypadł algorytm genetyczny, który charakteryzował się bardzo szybko rosnącym czasem wykonania przy jednoczesnym nie najlepszym wynikiem RMSE. \relax }{figure.caption.43}{}}
\newlabel{exp:momentum}{{4.3.1}{36}{}{subsubsection*.44}{}}
\gdef \LT@iv {\LT@entry 
    {1}{86.55678pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Konfiguracja dla eksperymentu dopasowania warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci\relax }}{37}{table.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymaln\IeC {\k a} warto\IeC {\'s}\IeC {\'c} wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy warto\IeC {\'s}ci\IeC {\k a} parametru a b\IeC {\l }\IeC {\k e}dem RMSE. W zakresie warto\IeC {\'s}ci $[0,0.9]$ b\IeC {\l }\IeC {\k a}d oscyluje w granicach podobnych warto\IeC {\'s}ci z nieznaczn\IeC {\k a} tendencj\IeC {\k a} malej\IeC {\k a}c\IeC {\k a}. Wyra\IeC {\'z}ny skok na niekorzy\IeC {\'s}\IeC {\'c} odnotowany jest dopiero przy momentum$=1$.\relax }}{37}{figure.caption.45}}
\newlabel{fig:expmomentum}{{4.5}{37}{Wyniki eksperymentu testującego optymalną wartość współczynnika bezwładności. Wykres przedstawia zależność pomiędzy wartością parametru a błędem RMSE. W zakresie wartości $[0,0.9]$ błąd oscyluje w granicach podobnych wartości z nieznaczną tendencją malejącą. Wyraźny skok na niekorzyść odnotowany jest dopiero przy momentum$=1$.\relax }{figure.caption.45}{}}
\newlabel{tab:expmomentum}{{4.4}{37}{}{table.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od warto\IeC {\'s}ci wsp\IeC {\'o}\IeC {\l }czynnika bezw\IeC {\l }adno\IeC {\'s}ci.\relax }}{37}{table.4.4}}
\gdef \LT@v {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\gdef \LT@vi {\LT@entry 
    {1}{76.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{41.12457pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Konfiguracja dla eksperymentu dopasowania wielko\IeC {\'s}ci populacji\relax }}{38}{table.4.5}}
\newlabel{tab:exppopulation}{{4.6}{38}{}{table.4.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru populacji.\relax }}{38}{table.4.6}}
\gdef \LT@vii {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{239.77191pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar populacji. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem a b\IeC {\l }\IeC {\k e}dem RMSE. Zgodnie z oczekiwaniami wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem populacji a czasem wykonania i ujemna pomi\IeC {\k e}dzy rozmiarem populacji a b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy rozmiarem populacji a czasem wykonania jest liniowa, natomiast b\IeC {\l }\IeC {\k a}d maleje wyk\IeC {\l }adniczo gdy populacja osi\IeC {\k a}ga wi\IeC {\k e}ksze rozmiary. Optymalnym zatem jest przyj\IeC {\k e}cie rozmiaru populacji r\IeC {\'o}wnej $100$.\relax }}{39}{figure.caption.47}}
\newlabel{fig:exppopulation}{{4.6}{39}{Wyniki eksperymentu testującego optymalny rozmiar populacji. Wykres przedstawia zależność pomiędzy rozmiarem a błędem RMSE. Zgodnie z oczekiwaniami występuje dodatnia korelacja pomiędzy rozmiarem populacji a czasem wykonania i ujemna pomiędzy rozmiarem populacji a błędem algorytmu rekomendacji. Zależność pomiędzy rozmiarem populacji a czasem wykonania jest liniowa, natomiast błąd maleje wykładniczo gdy populacja osiąga większe rozmiary. Optymalnym zatem jest przyjęcie rozmiaru populacji równej $100$.\relax }{figure.caption.47}{}}
\gdef \LT@viii {\LT@entry 
    {1}{92.06372pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{78.60742pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.5383pt}\LT@entry 
    {1}{56.1383pt}\LT@entry 
    {1}{56.1383pt}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w\relax }}{40}{table.4.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Wyniki eksperymentu testuj\IeC {\k a}cego optymalny rozmiar ukrytej warstwy neuron\IeC {\'o}w. Wykres przedstawia zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} pomi\IeC {\k e}dzy ilo\IeC {\'s}ci\IeC {\k a} neuron\IeC {\'o}w a b\IeC {\l }\IeC {\k e}dem RMSE. Wyniki prezentuj\IeC {\k a} si\IeC {\k e} odmiennie w zale\IeC {\.z}no\IeC {\'s}ci od typu algorytmu wykorzystanego do uczenia sieci. W przypadku algorytm\IeC {\'o}w propagacji wstecznej i RPROP wyst\IeC {\k e}puje dodatnia korelacja pomi\IeC {\k e}dzy rozmiarem warstwy ukrytej a b\IeC {\l }\IeC {\k e}dem algorytmu rekomendacji. Dla algorytmu BackProp optymalny rezultat osi\IeC {\k a}gni\IeC {\k e}ty zosta\IeC {\l } dla zaledwie jednego neuronu w warstwie ukrytej, dla algorytmu RPROP dla pi\IeC {\k e}ciu neuron\IeC {\'o}w. W tym ostatnim przypadku poprawa znajduje si\IeC {\k e} jednak na marginesie b\IeC {\l }\IeC {\k e}du statystycznego. W przypadku algorytmu genetycznego, niezale\IeC {\.z}nie od ilo\IeC {\'s}ci neuron\IeC {\'o}w wynik oscyluje na podobnym poziomie w zakresie testowanych warto\IeC {\'s}ci.\relax }}{40}{figure.caption.49}}
\newlabel{fig:exphiddenneural}{{4.7}{40}{Wyniki eksperymentu testującego optymalny rozmiar ukrytej warstwy neuronów. Wykres przedstawia zależność pomiędzy ilością neuronów a błędem RMSE. Wyniki prezentują się odmiennie w zależności od typu algorytmu wykorzystanego do uczenia sieci. W przypadku algorytmów propagacji wstecznej i RPROP występuje dodatnia korelacja pomiędzy rozmiarem warstwy ukrytej a błędem algorytmu rekomendacji. Dla algorytmu BackProp optymalny rezultat osiągnięty został dla zaledwie jednego neuronu w warstwie ukrytej, dla algorytmu RPROP dla pięciu neuronów. W tym ostatnim przypadku poprawa znajduje się jednak na marginesie błędu statystycznego. W przypadku algorytmu genetycznego, niezależnie od ilości neuronów wynik oscyluje na podobnym poziomie w zakresie testowanych wartości.\relax }{figure.caption.49}{}}
\newlabel{tab:exphiddenneural}{{4.8}{40}{}{table.4.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Zale\IeC {\.z}no\IeC {\'s}\IeC {\'c} b\IeC {\l }\IeC {\k e}du algorytmu RMSE od rozmiaru ukrytej warstwy neuronowej.\relax }}{40}{table.4.8}}
\gdef \LT@ix {\LT@entry 
    {1}{211.31915pt}\LT@entry 
    {1}{251.85992pt}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (NA KO\IeC {\'N}CU, BADANIA) Czy trzeba?}{41}{section*.51}}
\pgfsyspdfmark {pgfid11}{6749098}{47109715}
\pgfsyspdfmark {pgfid14}{37004660}{47126645}
\pgfsyspdfmark {pgfid15}{38671254}{46855763}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (NA KO\IeC {\'N}CU, BADANIA) Czy trzeba}{41}{section*.53}}
\pgfsyspdfmark {pgfid16}{6749098}{44291667}
\pgfsyspdfmark {pgfid19}{37004660}{44308597}
\pgfsyspdfmark {pgfid20}{38671254}{44037715}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuron\IeC {\'o}w\relax }}{41}{table.4.9}}
\newlabel{tab:optimummovielens}{{4.9}{41}{Konfiguracja dla eksperymentu dopasowania rozmiaru ukrytej warstwy neuronów\relax }{table.4.9}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ To samo dla AmazonMeta}{41}{section*.55}}
\pgfsyspdfmark {pgfid21}{6749098}{23314512}
\pgfsyspdfmark {pgfid24}{37004660}{23331442}
\pgfsyspdfmark {pgfid25}{38671254}{23060560}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2\relax .\kern .5em }Por\IeC {\'o}wnanie zaproponowanych algorytm\IeC {\'o}w hybrydowych z filtrowaniem z analiz\IeC {\k a} zawarto\IeC {\'s}ci i filtrowaniem kolaboratywnym}{41}{subsection.4.3.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (BADANIA) Por\IeC {\'o}wnanie algorytmu hybrydowego z content-based i collaborative}{41}{section*.62}}
\pgfsyspdfmark {pgfid26}{6749098}{4915651}
\pgfsyspdfmark {pgfid29}{37004660}{4932581}
\pgfsyspdfmark {pgfid30}{38671254}{4661699}
\newlabel{fig:exphybrid_movielens1a}{{\caption@xref {fig:exphybrid_movielens1a}{ on input line 1399}}{42}{}{figure.caption.57}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3\relax .\kern .5em }Analiza statystyczna wynik\IeC {\'o}w}{42}{subsection.4.3.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ (P\IeC {\'O}\IeC {\'Z}NIEJ) Analiza statystyczna wynik\IeC {\'o}w, PQStat}{42}{section*.68}}
\pgfsyspdfmark {pgfid31}{5816759}{11130438}
\pgfsyspdfmark {pgfid32}{2120848}{11147368}
\pgfsyspdfmark {pgfid33}{3787442}{10876486}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z analiz\IeC {\k a} zawarto\IeC {\'s}ci na podstawie danych z bazy MovieLense. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci.\relax }}{43}{figure.caption.58}}
\newlabel{fig:exphybrid_movielens1b}{{4.8}{43}{Porównanie algorytmu hybrydowego z analizą zawartości na podstawie danych z bazy MovieLense. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania z analizą zawartości.\relax }{figure.caption.58}{}}
\newlabel{fig:exphybrid_movielens2a}{{\caption@xref {fig:exphybrid_movielens2a}{ on input line 1415}}{44}{}{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy MovieLense. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania kolaboratywnego.\relax }}{45}{figure.caption.60}}
\newlabel{fig:exphybrid_movielens2b}{{4.9}{45}{Porównanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy MovieLense. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania kolaboratywnego.\relax }{figure.caption.60}{}}
\newlabel{fig:exphybrid_amazon1a}{{\caption@xref {fig:exphybrid_amazon1a}{ on input line 1440}}{46}{}{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z analiz\IeC {\k a} zawarto\IeC {\'s}ci na podstawie danych z bazy AmazonMeta. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania z analiz\IeC {\k a} zawarto\IeC {\'s}ci.\relax }}{47}{figure.caption.64}}
\newlabel{fig:exphybrid_amazon1b}{{4.10}{47}{Porównanie algorytmu hybrydowego z analizą zawartości na podstawie danych z bazy AmazonMeta. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania z analizą zawartości.\relax }{figure.caption.64}{}}
\newlabel{fig:exphybrid_amazon2a}{{\caption@xref {fig:exphybrid_amazon2a}{ on input line 1456}}{48}{}{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Por\IeC {\'o}wnanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy AmazonMeta. Skuteczno\IeC {\'s}\IeC {\'c} filtrowania z hybrydowego w zale\IeC {\.z}no\IeC {\'s}ci od liczby u\IeC {\.z}ytkownik\IeC {\'o}w i powtarzaj\IeC {\k a}cych si\IeC {\k e} cech. Pogrubiona linia przedstawia dzia\IeC {\l }anie filtrowania kolaboratywnego.\relax }}{49}{figure.caption.66}}
\newlabel{fig:exphybrid_amazon2b}{{4.11}{49}{Porównanie algorytmu hybrydowego z kolaboratywnym na podstawie danych z bazy AmazonMeta. Skuteczność filtrowania z hybrydowego w zależności od liczby użytkowników i powtarzających się cech. Pogrubiona linia przedstawia działanie filtrowania kolaboratywnego.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {chapter}{Rozdzia\l \ 5\relax .\kern .5em Wnioski}{51}{section*.69}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Wnioski}{51}{section*.70}}
\pgfsyspdfmark {pgfid36}{6749098}{34068051}
\pgfsyspdfmark {pgfid39}{37004660}{34084981}
\pgfsyspdfmark {pgfid40}{38671254}{33814099}
\@writefile{toc}{\contentsline {chapter}{Dodatek\ A\relax .\kern .5em Appendix 1}{53}{section*.71}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{iisthesis}
\bibdata{bibliography}
\bibcite{id:mgp}{1}
\bibcite{adomavicius2005toward}{2}
\bibcite{id:allegrofaq}{3}
\bibcite{effandpractstochsub}{4}
\bibcite{basu1998recommendation}{5}
\bibcite{bell2007modeling}{6}
\bibcite{bottou2012stochastic}{7}
\bibcite{id:celma2010music}{8}
\bibcite{id:NewRecommentationAlgoritmBasedOnSocialNetwork}{9}
\bibcite{claypool1999combining}{10}
\bibcite{id:TheYouTubeVideoRecommendationSystem}{11}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{55}{section*.73}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{id:ComprehensiveSurveyOfNeighborhoodBasedRecommendationMethods}{12}
\bibcite{id:filmwebfaq}{13}
\bibcite{mymedialite}{14}
\bibcite{gantner2011mymedialite}{15}
\bibcite{id:gupta2013wtf}{16}
\bibcite{harper2016movielens}{17}
\bibcite{haykin1994neural}{18}
\bibcite{hertz1993wstkep}{19}
\bibcite{id:FromTapestryToSVD}{20}
\bibcite{id:huynh2012modeling}{21}
\bibcite{hyndman2006another}{22}
\bibcite{id:imdbstats}{23}
\bibcite{id:NextSongRecommendationWithTemporalDynamics}{24}
\bibcite{aforgenet}{25}
\bibcite{aforgenetgenetic}{26}
\bibcite{koren2008factorization}{27}
\bibcite{koren2010factor}{28}
\bibcite{id:AdvancesInCollaborativeFiltering}{29}
\bibcite{koren2009matrix}{30}
\bibcite{kwateralgorytmy}{31}
\bibcite{lemire2005slope}{32}
\bibcite{leskovec2007dynamics}{33}
\bibcite{id:linden2003amazon}{34}
\bibcite{id:ContentBasedRecommenderSystemsState}{35}
\bibcite{id:MaleszkaMianowskaNguyenmethod}{36}
\bibcite{melville2002content}{37}
\bibcite{montana1989training}{38}
\bibcite{mymedialitedatasets}{39}
\bibcite{id:NetflixPrize}{40}
\bibcite{id:NetflixPrize2}{41}
\bibcite{id:NetflixPrizeRankings}{42}
\bibcite{id:NetflixPrizeRules}{43}
\bibcite{osowski1996sieci}{44}
\bibcite{pariser2011filter}{45}
\bibcite{pena2000evolutionary}{46}
\bibcite{id:aStreamOfMovies}{47}
\bibcite{rendle2008online}{48}
\bibcite{id:IntroductionToRecommenderSystemsHandbook}{49}
\bibcite{riedmiller1993direct}{50}
\bibcite{riedmiller1994rprop}{51}
\bibcite{id:ComputingRecommendationsExtremeScaleApacheFlink}{52}
\bibcite{id:RubensRecSysHB2010}{53}
\bibcite{salakhutdinov2011probabilistic}{54}
\bibcite{sarwar2000application}{55}
\bibcite{id:CollaborativeFilteringRecommenderSystems}{56}
\bibcite{id:EvolutionOfRecommenderSystems}{57}
\bibcite{timothy1996sieci}{58}
\bibcite{willmott2005advantages}{59}
\bibcite{yahoomusicwebsite}{60}
\bibcite{id:zhang2015hybrid}{61}
